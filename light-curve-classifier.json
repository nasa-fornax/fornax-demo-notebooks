{"version":3,"kind":"Notebook","sha256":"0c5621e121c021dba5bea7aef13f3fe2c72600c2bfa243e4be48ec86c6dd0ca5","slug":"light-curve-classifier","location":"/light_curves/light_curve_classifier.md","dependencies":[],"frontmatter":{"title":"Light Curve Classifier","kernelspec":{"name":"python3","display_name":"py-light_curve_classifier","language":"python"},"jupytext":{"text_representation":{"extension":".md","format_name":"myst","format_version":"0.13","jupytext_version":"1.16.0"}},"content_includes_title":false,"authors":[{"id":"Fornax developers and scientists","name":"Fornax developers and scientists"}],"github":"https://github.com/nasa-fornax/fornax-demo-notebooks","subject":"Fornax Demo Notebooks","keywords":["astronomy"],"settings":{"output_matplotlib_strings":"remove"},"numbering":{"title":{"offset":1}},"source_url":"https://github.com/nasa-fornax/fornax-demo-notebooks/blob/main/light_curves/light_curve_classifier.md","edit_url":"https://github.com/nasa-fornax/fornax-demo-notebooks/edit/main/light_curves/light_curve_classifier.md","exports":[{"format":"md","filename":"light_curve_classifier.md","url":"/fornax-demo-notebooks/build/light_curve_classifi-ce41b0c0c3056a9a72d5d398ce8db583.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"Learning Goals","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"wJlYbHn1hs"}],"identifier":"learning-goals","label":"Learning Goals","html_id":"learning-goals","implicit":true,"key":"VYHt9Qwl47"},{"type":"paragraph","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"children":[{"type":"text","value":"By the end of this tutorial, you will be able to:","position":{"start":{"line":18,"column":1},"end":{"line":18,"column":1}},"key":"lLpsh1WZNk"}],"key":"E6RNHIatk0"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":19,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"prepare data for ML algorithms by cleaning and filtering the dataset","position":{"start":{"line":19,"column":1},"end":{"line":19,"column":1}},"key":"FhhiaAQiqB"}],"key":"KykuXFSTOS"}],"key":"aIM7JfsOYv"},{"type":"listItem","spread":true,"position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"work with Pandas dataframes as a way of storing and manipulating time domain datasets","position":{"start":{"line":20,"column":1},"end":{"line":20,"column":1}},"key":"ZVFFRgCmlZ"}],"key":"zhLBesPv6G"}],"key":"ih2koH4n2I"},{"type":"listItem","spread":true,"position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"use ","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"JwYrGjqkGO"},{"type":"link","url":"https://www.sktime.net/en/stable/index.html","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"children":[{"type":"text","value":"sktime","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"HESMN4Srvx"}],"urlSource":"https://www.sktime.net/en/stable/index.html","key":"MlBfom40yF"},{"type":"text","value":" algorithms to train a classifier and calculate metrics of accuracy","position":{"start":{"line":21,"column":1},"end":{"line":21,"column":1}},"key":"eo5BkxHsuq"}],"key":"lgy2p8F7K4"}],"key":"atPdxEqkMb"},{"type":"listItem","spread":true,"position":{"start":{"line":22,"column":1},"end":{"line":23,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"use the trained classifier to predict labels on an unlabelled dataset","position":{"start":{"line":22,"column":1},"end":{"line":22,"column":1}},"key":"QTzzfRsGwg"}],"key":"K4I1RZAIeo"}],"key":"yKVVA9YEYE"}],"key":"hxXPOjTeVL"},{"type":"heading","depth":2,"position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"children":[{"type":"text","value":"Introduction","position":{"start":{"line":24,"column":1},"end":{"line":24,"column":1}},"key":"AvXro41hNQ"}],"identifier":"introduction","label":"Introduction","html_id":"introduction","implicit":true,"key":"ZpaZU1BF5h"},{"type":"paragraph","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"children":[{"type":"text","value":"The science goal of this notebook is to find a classifier that can accurately discern changing look active galactic nuclei (CLAGN) from a broad sample of all Sloan Digital Sky Survey (SDSS) identified Quasars (QSOs) based solely on archival photometry in the form of multiwavelength light curves.","position":{"start":{"line":26,"column":1},"end":{"line":26,"column":1}},"key":"GMBKJDoh8h"}],"key":"ZTHT0YTbx3"},{"type":"paragraph","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"children":[{"type":"text","value":"CLAGN are astrophysically interesting objects because they appear to change state.  CLAGN are characterized by the appearance or disappearance of broad emission lines on timescales of order months.  Astronomers would like to understand the physical mechanism behind this apparent change of state.  However, only a few hundered CLAGN are known, and finding CLAGN is observationally expensive, traditionally requiring multiple epochs of spectroscopy.  Being able to identify CLAGN in existing, archival, large, photometric samples would allow us to identify a statisitcally significant sample from which we could better understand the underlying physics.","position":{"start":{"line":28,"column":1},"end":{"line":28,"column":1}},"key":"RLRuu3ySIt"}],"key":"Ukzl7XlsYl"},{"type":"paragraph","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"children":[{"type":"text","value":"This notebook walks through an exercise in using multiwavelength photometry(no spectroscopy) to learn if we can identify CLAGN based on their light curves alone.  If we are able to find a classifier that can differentiate CLAGN from SDSS QSOs, we would then be able to run the entire sample of SDSS QSOs (~500,000) to find additional CLAGN candidates for follow-up verification.","position":{"start":{"line":30,"column":1},"end":{"line":30,"column":1}},"key":"LMOrzaXA1q"}],"key":"MD3KVf8CRd"},{"type":"paragraph","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"Input to this notebook is output of a previous demo notebook which generates multiwavelength light curves from archival data.  This notebook starts with light curves, does data prep, and runs the light curves through multiple ML classification algorithms.  There are many ML algorthms to choose from; We choose to use sktime algorithms for time domain classification beacuse it is a library of many algorithms specifically tailored to time series datasets.  It is based on the ","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"smJtWkjxT0"},{"type":"link","url":"https://scikit-learn.org/stable/index.html","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"children":[{"type":"text","value":"scikit-learn","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"ex5JHqtO4v"}],"urlSource":"https://scikit-learn.org/stable/index.html","key":"gVrwQKL8b5"},{"type":"text","value":" library so syntax is familiar to many users.","position":{"start":{"line":32,"column":1},"end":{"line":32,"column":1}},"key":"mXzQkAdY8w"}],"key":"zvfHlwfLNM"},{"type":"paragraph","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"children":[{"type":"text","value":"The challenges of this time-domain dataset for ML work are:","position":{"start":{"line":34,"column":1},"end":{"line":34,"column":1}},"key":"t6hXekiAZr"}],"key":"grbhXVPVBW"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":35,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Multi-variate = There are multiple bands of observations per target (13+)","position":{"start":{"line":35,"column":1},"end":{"line":35,"column":1}},"key":"FSc5B1pazX"}],"key":"KrDxdt1d4I"}],"key":"lNeEiem1Oa"},{"type":"listItem","spread":true,"position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Unequal length = Each band has a light curve with different sampling than other bands","position":{"start":{"line":36,"column":1},"end":{"line":36,"column":1}},"key":"A1shUEUkGY"}],"key":"NnviCNo3D5"}],"key":"tDns9bZP4q"},{"type":"listItem","spread":true,"position":{"start":{"line":37,"column":1},"end":{"line":38,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Missing data = Not each object has all observations in all bands","position":{"start":{"line":37,"column":1},"end":{"line":37,"column":1}},"key":"aaEHYfU0oh"}],"key":"YPDshsJEtX"}],"key":"T6cONLIjjU"}],"key":"tn2uYMegNv"},{"type":"heading","depth":3,"position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"children":[{"type":"text","value":"Input","position":{"start":{"line":39,"column":1},"end":{"line":39,"column":1}},"key":"W6w7ceFKrn"}],"identifier":"input","label":"Input","html_id":"input","implicit":true,"key":"TTPuCsdk2M"},{"type":"paragraph","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"children":[{"type":"text","value":"Light curve parquet file of multiwavelength light curves from the light_curve_collector.md demo notebook in this same repo.  The format of the light curves is a Pandas multiindex data frame.","position":{"start":{"line":41,"column":1},"end":{"line":41,"column":1}},"key":"bJRr86wzUi"}],"key":"WJJEzSsKIl"},{"type":"paragraph","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"children":[{"type":"text","value":"We choose to use a Pandas multiindex dataframe to store and work with the data because it fulfills these requirements:","position":{"start":{"line":43,"column":1},"end":{"line":43,"column":1}},"key":"wqXLxoJkvu"}],"key":"pUMTSVd47m"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":44,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"It can handle the above challenges of a dataset = multi-variate, unqueal length with missing data.","position":{"start":{"line":44,"column":1},"end":{"line":44,"column":1}},"key":"i8eeShUJPu"}],"key":"iBIIcrzZuY"}],"key":"GVMCF14rty"},{"type":"listItem","spread":true,"position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Multiple targets (multiple rows)","position":{"start":{"line":45,"column":1},"end":{"line":45,"column":1}},"key":"i5d4THlq2Y"}],"key":"PyXB5urMcn"}],"key":"T3UBAjWv9R"},{"type":"listItem","spread":true,"position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Pandas has some built in understanding of time units","position":{"start":{"line":46,"column":1},"end":{"line":46,"column":1}},"key":"FAiZ8O7pYM"}],"key":"WpQqPwfOOD"}],"key":"JIFd4fyV33"},{"type":"listItem","spread":true,"position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Can be scaled up to big data numbers of rows (altough we don’t push to out of memory structures in this use case)","position":{"start":{"line":47,"column":1},"end":{"line":47,"column":1}},"key":"Z1P0E53oWK"}],"key":"NMzKEJ4qLo"}],"key":"ktVqcgGUeO"},{"type":"listItem","spread":true,"position":{"start":{"line":48,"column":1},"end":{"line":49,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Pandas is user friendly with a lot of existing functionality","position":{"start":{"line":48,"column":1},"end":{"line":48,"column":1}},"key":"HrJtTiSqia"}],"key":"Iu4Ju9OrLa"}],"key":"VIV5cac86g"}],"key":"ECyZ5yJ6Kr"},{"type":"paragraph","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"children":[{"type":"text","value":"A useful reference for what sktime expects as input to its ML algorithms: ","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"key":"T7aufMM0Mk"},{"type":"link","url":"https://github.com/sktime/sktime/blob/main/examples/AA_datatypes_and_datasets.ipynb","position":{"start":{"line":50,"column":1},"end":{"line":50,"column":1}},"children":[{"type":"text","value":"examples​/AA​_datatypes​_and​_datasets​.ipynb","key":"bwV6h1DfWW"}],"urlSource":"https://github.com/sktime/sktime/blob/main/examples/AA_datatypes_and_datasets.ipynb","data":{"kind":"file","org":"sktime","repo":"sktime","reference":"main","file":"examples/AA_datatypes_and_datasets.ipynb","raw":"https://raw.githubusercontent.com/sktime/sktime/main/examples/AA_datatypes_and_datasets.ipynb"},"internal":false,"protocol":"github","key":"gQPrRCXMKg"}],"key":"vMajQ1WcC1"},{"type":"heading","depth":3,"position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"children":[{"type":"text","value":"Output","position":{"start":{"line":52,"column":1},"end":{"line":52,"column":1}},"key":"PMjDNiivDt"}],"identifier":"output","label":"Output","html_id":"output","implicit":true,"key":"UTLV6yvovh"},{"type":"paragraph","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"children":[{"type":"text","value":"Trained classifiers as well as estimates of their accuracy and plots of confusion matrices","position":{"start":{"line":54,"column":1},"end":{"line":54,"column":1}},"key":"L5Kfea4osh"}],"key":"w3vtQY0i6Z"},{"type":"heading","depth":3,"position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"children":[{"type":"text","value":"Runtime","position":{"start":{"line":56,"column":1},"end":{"line":56,"column":1}},"key":"OQQsn1JyU0"}],"identifier":"runtime","label":"Runtime","html_id":"runtime","implicit":true,"key":"FKat4OPBJa"},{"type":"paragraph","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"children":[{"type":"text","value":"As of 2024 August, this notebook takes ~170s to run to completion on Fornax using a server with 16GB RAM/ 4CPU.","position":{"start":{"line":58,"column":1},"end":{"line":58,"column":1}},"key":"HG4pC9cnxK"}],"key":"cAM5mCX50j"},{"type":"heading","depth":2,"position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"children":[{"type":"text","value":"Imports","position":{"start":{"line":60,"column":1},"end":{"line":60,"column":1}},"key":"MIepwkd6ef"}],"identifier":"imports","label":"Imports","html_id":"imports","implicit":true,"key":"B7mEwKpQm8"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":62,"column":1},"end":{"line":74,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"pandas","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"y0K2MQ9S91"},{"type":"text","value":" to work with light curve data structure","position":{"start":{"line":62,"column":1},"end":{"line":62,"column":1}},"key":"kxGGMIM49f"}],"key":"o9ObDCZ6C9"}],"key":"DaFrrLSRYk"},{"type":"listItem","spread":true,"position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"numpy","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"LcVGlVAguu"},{"type":"text","value":" for numerical calculations","position":{"start":{"line":63,"column":1},"end":{"line":63,"column":1}},"key":"Zsce9Cs6du"}],"key":"hJSzFTt9Rk"}],"key":"T2p3OuSMml"},{"type":"listItem","spread":true,"position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"matplotlib","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"key":"UbR7jKBOzS"},{"type":"text","value":" for plotting","position":{"start":{"line":64,"column":1},"end":{"line":64,"column":1}},"key":"LkxnJwLYLO"}],"key":"iYhosMPEQ7"}],"key":"xE1Jv1cvR8"},{"type":"listItem","spread":true,"position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"sys","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"ZyL3mptNrU"},{"type":"text","value":" for paths","position":{"start":{"line":65,"column":1},"end":{"line":65,"column":1}},"key":"DyodSVbx43"}],"key":"GPUiBQy6rI"}],"key":"HaWPwmnXsS"},{"type":"listItem","spread":true,"position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"astropy","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"cjiybelsnu"},{"type":"text","value":" to work with coordinates/units and data structures","position":{"start":{"line":66,"column":1},"end":{"line":66,"column":1}},"key":"t3u8f3bZJk"}],"key":"YGH8G4Hgym"}],"key":"JSNrlXUVZr"},{"type":"listItem","spread":true,"position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"tqdm","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"HgeoZqlFaH"},{"type":"text","value":" for showing progress meter","position":{"start":{"line":67,"column":1},"end":{"line":67,"column":1}},"key":"lY4OiAJbvE"}],"key":"dCLNLKxyEk"}],"key":"aiQ3SWBgY4"},{"type":"listItem","spread":true,"position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"sktime","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"Oie8NSv4BI"},{"type":"text","value":" ML algorithms specifically for time-domain data","position":{"start":{"line":68,"column":1},"end":{"line":68,"column":1}},"key":"WObGfhj0SI"}],"key":"sEIxIabkdl"}],"key":"ee4l3zxtmO"},{"type":"listItem","spread":true,"position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"sklearn","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"qumpJq2rKG"},{"type":"text","value":" general use ML algorthims with easy to use interface","position":{"start":{"line":69,"column":1},"end":{"line":69,"column":1}},"key":"si0B2pa1vf"}],"key":"IzqUxboe0B"}],"key":"bu5ZW4z94r"},{"type":"listItem","spread":true,"position":{"start":{"line":70,"column":1},"end":{"line":70,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"scipy","position":{"start":{"line":70,"column":1},"end":{"line":70,"column":1}},"key":"s1Do8VOWUC"},{"type":"text","value":" for statistical analysis","position":{"start":{"line":70,"column":1},"end":{"line":70,"column":1}},"key":"rmGvtP4w9G"}],"key":"BWQwCt6qFl"}],"key":"M8aCdQIMb1"},{"type":"listItem","spread":true,"position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"json","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"xcBh6ke0FD"},{"type":"text","value":" for storing intermediate files","position":{"start":{"line":71,"column":1},"end":{"line":71,"column":1}},"key":"JEhYCSLE24"}],"key":"iVwr2UHQs0"}],"key":"xWYdRFLk1q"},{"type":"listItem","spread":true,"position":{"start":{"line":72,"column":1},"end":{"line":74,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"google_drive_downloader","position":{"start":{"line":72,"column":1},"end":{"line":72,"column":1}},"key":"QSuUx4CLB2"},{"type":"text","value":" to access files stored in google drive","position":{"start":{"line":72,"column":1},"end":{"line":72,"column":1}},"key":"ps0WfS7WIq"}],"key":"O4qkdbIdqe"}],"key":"nOyhHZzqGP"}],"key":"DXa6WRfqDn"},{"type":"paragraph","position":{"start":{"line":75,"column":1},"end":{"line":75,"column":1}},"children":[{"type":"text","value":"This cell will install them if needed:","position":{"start":{"line":75,"column":1},"end":{"line":75,"column":1}},"key":"dRFrwGCJfc"}],"key":"rKLmPQQyyu"}],"key":"ouiSC9NIMN"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Uncomment the next line to install dependencies if needed.\n# %pip install -r requirements_light_curve_classifier.txt","key":"aPoSFHixJ5"},{"type":"outputs","id":"CzXL44YyCnG5gL0LP0E8t","children":[],"key":"hz1by8I7gD"}],"key":"FfUgH41OhV"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import sys\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nimport pandas as pd\nfrom astropy.table import Table\nimport googledrivedownloader as gdd\nfrom tqdm.auto import tqdm\nimport json\n\nfrom sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import RBF\n\nfrom sktime.classification.deep_learning import CNNClassifier\nfrom sktime.classification.dictionary_based import IndividualTDE\nfrom sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\nfrom sktime.classification.dummy import DummyClassifier\nfrom sktime.classification.ensemble import WeightedEnsembleClassifier\nfrom sktime.classification.feature_based import Catch22Classifier, RandomIntervalClassifier\nfrom sktime.classification.hybrid import HIVECOTEV2\nfrom sktime.classification.interval_based import CanonicalIntervalForest\nfrom sktime.classification.kernel_based import Arsenal, RocketClassifier\nfrom sktime.classification.shapelet_based import ShapeletTransformClassifier\nfrom sktime.registry import all_estimators, all_tags\nfrom sktime.datatypes import check_is_mtype\n\n# local code imports\nsys.path.append('code_src/')\nfrom classifier_functions import sigmaclip_lightcurves, remove_objects_without_band, \\\nremove_incomplete_data, missingdata_to_zeros, missingdata_drop_bands, \\\nuniform_length_spacing, reformat_df, local_normalization_max, mjd_to_datetime\n\n#improves memory usage and avoids problems that trigger warnings\npd.options.mode.copy_on_write = True","key":"rsTnRW5wm3"},{"type":"outputs","id":"Cxoa54LQL-J0c0y2hNB6E","children":[],"key":"WqHpFr62Hx"}],"key":"Sp8uZUeiVk"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"children":[{"type":"text","value":"1. Read in a dataset of archival light curves","position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"key":"hPF8Nevqjv"}],"identifier":"id-1-read-in-a-dataset-of-archival-light-curves","label":"1. Read in a dataset of archival light curves","html_id":"id-1-read-in-a-dataset-of-archival-light-curves","implicit":true,"key":"KgrSgP2L5Z"},{"type":"paragraph","position":{"start":{"line":123,"column":1},"end":{"line":123,"column":1}},"children":[{"type":"text","value":"We use here a sample of AGN including known CLAGN & random SDSS AGN","position":{"start":{"line":123,"column":1},"end":{"line":123,"column":1}},"key":"CtxdpfnuEy"}],"key":"yFqqNMk8v7"},{"type":"paragraph","position":{"start":{"line":125,"column":1},"end":{"line":125,"column":1}},"children":[{"type":"text","value":"If you want to use your own sample, you can use the code from the ","position":{"start":{"line":125,"column":1},"end":{"line":125,"column":1}},"key":"KlrDnR3Ht0"},{"type":"link","url":"/light-curve-collector","position":{"start":{"line":125,"column":1},"end":{"line":125,"column":1}},"children":[{"type":"text","value":"light curve collector notebook","position":{"start":{"line":125,"column":1},"end":{"line":125,"column":1}},"key":"ZAEkhDnyJ3"}],"urlSource":"light_curve_collector.md","dataUrl":"/light-curve-collector.json","internal":true,"protocol":"file","key":"oVBEHBaUGy"},{"type":"text","value":" in this same repo to make the required pandas dataframe which you will need to run this notebook.","position":{"start":{"line":125,"column":1},"end":{"line":125,"column":1}},"key":"Xo3RGiKsd1"}],"key":"bQhkUJ3h8H"}],"key":"deUT5k4UQI"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# First we want to load light curves made in the light_curve_collector notebook\n\n# The data is on google drive, this will download it for you and read it into\n# a pandas dataframe\nsavename_df_lc = './data/small_CLAGN_SDSS_df_lc.parquet'\ngdd.download_file_from_google_drive(file_id='1DrB-CWdBBBYuO0WzNnMl5uQnnckL7MWH',\n                                    dest_path=savename_df_lc,\n                                    unzip=True)\n\n#load the data into a pandas dataframe\ndf_lc = pd.read_parquet(savename_df_lc)","key":"W6PyitWFp2"},{"type":"outputs","id":"MF5MR_nx1JW8V_U5foumJ","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Downloading 1DrB-CWdBBBYuO0WzNnMl5uQnnckL7MWH into ./data/small_CLAGN_SDSS_df_lc.parquet... "},"key":"SjE3CnaarL"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Done.\nUnzipping..."},"key":"frvFBZexc2"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stderr","text":"/home/runner/work/fornax-demo-notebooks/fornax-demo-notebooks/.tox/py312-buildhtml/lib/python3.12/site-packages/googledrivedownloader/download.py:88: UserWarning: Ignoring `unzip` since \"1DrB-CWdBBBYuO0WzNnMl5uQnnckL7MWH\" does not look like a valid zip file\n  warnings.warn('Ignoring `unzip` since \"{}\" does not look like a valid zip file'.format(file_id))\n"},"key":"d2nz468MzJ"}],"key":"QxtpslIXZo"}],"key":"JCIyGNhsVm"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#get rid of indices set in the light curve code and reset them as needed\n#before sktime algorithms\ndf_lc = df_lc.reset_index()\n\n#what does the dataset look like at the start?\ndf_lc","key":"RYbZfn97NM"},{"type":"outputs","id":"npZgz6jhvC-p6zTp28pDp","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"execute_result","execution_count":4,"metadata":{},"data":{"text/plain":{"content":"        objectid       label        band          time      flux  err\n0             15  MacLeod 19  SAXGRBMGRB  50335.861597  0.100000  0.1\n1            240        SDSS  SAXGRBMGRB  51601.900023  0.100000  0.1\n2            364        SDSS  SAXGRBMGRB  50594.078796  0.100000  0.1\n3            169        SDSS  SAXGRBMGRB  51373.759595  0.100000  0.1\n4            446        SDSS  SAXGRBMGRB  50991.525394  0.100000  0.1\n...          ...         ...         ...           ...       ...  ...\n458312       453        SDSS          K2  60148.521180  1.020081  NaN\n458313       453        SDSS          K2  60149.195427  1.014221  NaN\n458314       453        SDSS          K2  60149.930970  1.009093  NaN\n458315       453        SDSS          K2  60150.584787  1.003534  NaN\n458316       453        SDSS          K2  60151.238603  1.000992  NaN\n\n[458317 rows x 6 columns]","content_type":"text/plain"},"text/html":{"content":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>objectid</th>\n      <th>label</th>\n      <th>band</th>\n      <th>time</th>\n      <th>flux</th>\n      <th>err</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15</td>\n      <td>MacLeod 19</td>\n      <td>SAXGRBMGRB</td>\n      <td>50335.861597</td>\n      <td>0.100000</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>240</td>\n      <td>SDSS</td>\n      <td>SAXGRBMGRB</td>\n      <td>51601.900023</td>\n      <td>0.100000</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>364</td>\n      <td>SDSS</td>\n      <td>SAXGRBMGRB</td>\n      <td>50594.078796</td>\n      <td>0.100000</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>169</td>\n      <td>SDSS</td>\n      <td>SAXGRBMGRB</td>\n      <td>51373.759595</td>\n      <td>0.100000</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>446</td>\n      <td>SDSS</td>\n      <td>SAXGRBMGRB</td>\n      <td>50991.525394</td>\n      <td>0.100000</td>\n      <td>0.1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>458312</th>\n      <td>453</td>\n      <td>SDSS</td>\n      <td>K2</td>\n      <td>60148.521180</td>\n      <td>1.020081</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>458313</th>\n      <td>453</td>\n      <td>SDSS</td>\n      <td>K2</td>\n      <td>60149.195427</td>\n      <td>1.014221</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>458314</th>\n      <td>453</td>\n      <td>SDSS</td>\n      <td>K2</td>\n      <td>60149.930970</td>\n      <td>1.009093</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>458315</th>\n      <td>453</td>\n      <td>SDSS</td>\n      <td>K2</td>\n      <td>60150.584787</td>\n      <td>1.003534</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>458316</th>\n      <td>453</td>\n      <td>SDSS</td>\n      <td>K2</td>\n      <td>60151.238603</td>\n      <td>1.000992</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>458317 rows × 6 columns</p>\n</div>","content_type":"text/html"}}},"key":"cnxIMoCMWM"}],"key":"ChJkXcUFml"}],"key":"xL7hRzxCGu"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":150,"column":1},"end":{"line":150,"column":1}},"children":[{"type":"text","value":"2. Data Prep","position":{"start":{"line":150,"column":1},"end":{"line":150,"column":1}},"key":"PBR8PqIHHc"}],"identifier":"id-2-data-prep","label":"2. Data Prep","html_id":"id-2-data-prep","implicit":true,"key":"qEdVjZWQvG"},{"type":"paragraph","position":{"start":{"line":152,"column":1},"end":{"line":152,"column":1}},"children":[{"type":"text","value":"The majority of work in all ML projects is preparing and cleaning the data.  As most do, this dataset needs significant work before it can be fed into a ML algorithm.  Data preparation includes everything from removing statistical outliers to putting it in the correct data format for the algorithms.","position":{"start":{"line":152,"column":1},"end":{"line":152,"column":1}},"key":"VEHzuoblPx"}],"key":"jsb4JfvCal"}],"key":"ZJ9q1WBmjg"},{"type":"block","position":{"start":{"line":154,"column":1},"end":{"line":154,"column":1}},"children":[{"type":"heading","depth":3,"position":{"start":{"line":156,"column":1},"end":{"line":156,"column":1}},"children":[{"type":"text","value":"2.1 Remove bands with not enough data","position":{"start":{"line":156,"column":1},"end":{"line":156,"column":1}},"key":"jO7XnCMnZt"}],"identifier":"id-2-1-remove-bands-with-not-enough-data","label":"2.1 Remove bands with not enough data","html_id":"id-2-1-remove-bands-with-not-enough-data","implicit":true,"key":"VKXOjlCQMx"},{"type":"paragraph","position":{"start":{"line":158,"column":1},"end":{"line":160,"column":1}},"children":[{"type":"text","value":"For this use case of CLAGN classification, we don’t need to include some of the bands\nthat are known to be sparse.  Most ML algorithms cannot handle sparse data so one way to accomodate that\nis to remove the sparsest datasets.","position":{"start":{"line":158,"column":1},"end":{"line":158,"column":1}},"key":"i0S2yx1fZQ"}],"key":"o2msrX2AL0"}],"key":"sbK2D0XMlO"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"##what are the unique set of bands included in our light curves\ndf_lc.band.unique()\n\n#get rid of some of the bands that don't have enough data for all the sources\n#CLAGN are generall fainter targets, and therefore mostly not found\n#in datasets like TESS & K2\n\nbands_to_drop = [\"IceCube\", \"TESS\", \"FERMIGTRIG\", \"K2\"]\ndf_lc = df_lc[~df_lc[\"band\"].isin(bands_to_drop)]","key":"Z0RK3PkTA0"},{"type":"outputs","id":"wtqGUKgiAXMWJUqrBhBA5","children":[],"key":"qIPpidlM4O"}],"key":"NlF1SpuB8U"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"children":[{"type":"text","value":"2.2 Combine Labels for a Simpler Classification","position":{"start":{"line":174,"column":1},"end":{"line":174,"column":1}},"key":"ASTM4XA2B4"}],"identifier":"id-2-2-combine-labels-for-a-simpler-classification","label":"2.2 Combine Labels for a Simpler Classification","html_id":"id-2-2-combine-labels-for-a-simpler-classification","implicit":true,"key":"WkMOkLDwOj"},{"type":"paragraph","position":{"start":{"line":176,"column":1},"end":{"line":176,"column":1}},"children":[{"type":"text","value":"All CLAGN start in the dataset as having labels based on their discovery paper.  Because we want one sample with all known CLAGN, we change those discovery names to be simply “CLAGN” for all CLAGN, regardless of origin.","position":{"start":{"line":176,"column":1},"end":{"line":176,"column":1}},"key":"NELjAfdqba"}],"key":"wtMx782jm7"}],"key":"g36YEQFuN1"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"df_lc['label'] = df_lc.label.str.replace('MacLeod 16', 'CLAGN')\ndf_lc['label'] = df_lc.label.str.replace('LaMassa 15', 'CLAGN')\ndf_lc['label'] = df_lc.label.str.replace('Yang 18', 'CLAGN')\ndf_lc['label'] = df_lc.label.str.replace('Lyu 22', 'CLAGN')\ndf_lc['label'] = df_lc.label.str.replace('Hon 22', 'CLAGN')\ndf_lc['label'] = df_lc.label.str.replace('Sheng 20', 'CLAGN')\ndf_lc['label'] = df_lc.label.str.replace('MacLeod 19', 'CLAGN')\ndf_lc['label'] = df_lc.label.str.replace('Green 22', 'CLAGN')\ndf_lc['label'] = df_lc.label.str.replace('Lopez-Navas 22', 'CLAGN')","key":"uxUaRl1HHZ"},{"type":"outputs","id":"ua-p29XZOL885iiDZosLp","children":[],"key":"M9mjACejai"}],"key":"ApMdG0SGbO"},{"type":"block","children":[],"key":"l00St5eHDE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"print(df_lc.groupby([\"objectid\"]).ngroups, \"n objects before removing missing band data\")","key":"Kw83gUzxE5"},{"type":"outputs","id":"5WsNEMKRI4aJZ07hrEQwB","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"451 n objects before removing missing band data\n"},"key":"fG2gs1xa1J"}],"key":"ZupZe7xZh9"}],"key":"YJbd1G2SZp"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"children":[{"type":"text","value":"2.3 Data Visualization","position":{"start":{"line":194,"column":1},"end":{"line":194,"column":1}},"key":"KVg3HyYjoF"}],"identifier":"id-2-3-data-visualization","label":"2.3 Data Visualization","html_id":"id-2-3-data-visualization","implicit":true,"key":"i5UmvVnKG0"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":196,"column":1},"end":{"line":197,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":196,"column":1},"end":{"line":197,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"can we see any trends by examining plots of a subset of the data?","position":{"start":{"line":196,"column":1},"end":{"line":196,"column":1}},"key":"DrZJRSBrOP"}],"key":"dBWt7IzO6y"}],"key":"xxTBY6LSdb"}],"key":"wLZ7IN5o76"}],"key":"it4JDcvgt9"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#chhose your own adventure, the bands from which you can choose are:\ndf_lc.band.unique()","key":"gQsSXWZpKp"},{"type":"outputs","id":"GGQvjsjn5bniZKg9Fqv8v","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"execute_result","execution_count":8,"metadata":{},"data":{"text/plain":{"content":"array(['SAXGRBMGRB', 'G', 'BP', 'RP', 'panstarrs i', 'panstarrs y',\n       'panstarrs z', 'panstarrs g', 'panstarrs r', 'zg', 'zi', 'zr',\n       'W1', 'W2', 'k2'], dtype=object)","content_type":"text/plain"}}},"key":"L5mmmJN6je"}],"key":"qZEmWqQL4l"}],"key":"zd1ZmuS21a"},{"type":"block","children":[],"key":"TmqF85qdOE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#plot a single band for all objects\nband_of_interest = 'zr'\nband_lc = df_lc[df_lc['band'] == band_of_interest]\n#reset zero time to be start of that mission\nband_lc[\"time\"] = band_lc[\"time\"] - band_lc[\"time\"].min()\nband_lc.time.min()\n\nband_lc.set_index('time', inplace = True)  #helps with the plotting\n\n#drop some objects to try to clear up plot\nquerystring1 = 'objectid < 162'\nquerystring2 = 'objectid > 200'\nband_lc = band_lc.drop(band_lc.query(querystring1 ).index)\nband_lc = band_lc.drop(band_lc.query(querystring2 ).index)\n\n#quick normalization for plotting\n#we normalize for real after cleaning the data\n# make a new column with max_r_flux for each objectid\nband_lc['mean_band'] = band_lc.groupby('objectid', sort=False)[\"flux\"].transform('mean')\nband_lc['sigma_band'] = band_lc.groupby('objectid', sort=False)[\"flux\"].transform('std')\n\n#choose to normalize (flux - mean) / sigma\nband_lc['flux'] = (band_lc['flux'] - band_lc['mean_band']).div(band_lc['sigma_band'], axis=0)\n\n#want to have two different sets so I can color code\nclagn_df = band_lc[band_lc['label'] == 'CLAGN']\nsdss_df = band_lc[band_lc['label'] == 'SDSS']\nprint(clagn_df.groupby([\"objectid\"]).ngroups, \"n objects CLAGN \")\nprint(sdss_df.groupby([\"objectid\"]).ngroups, \"n objects SDSS \")\n\n#groupy objectid & plot flux vs. time\nfig, ax = plt.subplots(figsize=(10,6))\nlc_sdss = sdss_df.groupby(['objectid'])['flux'].plot(kind='line', ax=ax, color = 'gray', label = 'SDSS', linewidth = 0.3)\nlc_clagn = clagn_df.groupby(['objectid'])['flux'].plot(kind='line', ax=ax, color = 'orange', label = 'CLAGN', linewidth = 1)\n\n#add legend and labels/titles\nlegend_elements = [Line2D([0], [0], color='orange', lw=4, label='CLAGN'),\n                   Line2D([0], [0], color='gray', lw=4, label='SDSS')]\nax.legend(handles=legend_elements, loc='best')\n\nax.set_ylabel('Normalized Flux')\nax.set_xlabel('Time in days since start of mission')\nplt.title(f\"{band_of_interest} light curves\")\n\n#tailored to ZTF r band with lots of data\nax.set_ylim([-2, 4])\nax.set_xlim([1000, 1250])","key":"rvJNc72E9F"},{"type":"outputs","id":"DZiZFe46FqI3rykHOIhgT","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"2 n objects CLAGN \n34 n objects SDSS \n"},"key":"eIfVROVqAt"},{"type":"output","children":[],"jupyter_data":{"output_type":"execute_result","execution_count":9,"metadata":{},"data":{"text/plain":{"content":"(1000.0, 1250.0)","content_type":"text/plain"}}},"key":"qakwcvRnL9"},{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 1000x600 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"1d8b36596afa57ec340f6117b5fcb23c","path":"/fornax-demo-notebooks/build/1d8b36596afa57ec340f6117b5fcb23c.png"}}},"key":"K1MFkZ8gS4"}],"key":"o22ojIJmB4"}],"key":"f9t8Yn6Igk"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":253,"column":1},"end":{"line":253,"column":1}},"children":[{"type":"text","value":"2.4 Clean the dataset of unwanted data","position":{"start":{"line":253,"column":1},"end":{"line":253,"column":1}},"key":"l5FqCHoCw4"}],"identifier":"id-2-4-clean-the-dataset-of-unwanted-data","label":"2.4 Clean the dataset of unwanted data","html_id":"id-2-4-clean-the-dataset-of-unwanted-data","implicit":true,"key":"Z08XLsvIlE"},{"type":"paragraph","position":{"start":{"line":255,"column":1},"end":{"line":255,"column":1}},"children":[{"type":"text","value":"“unwanted” includes:","position":{"start":{"line":255,"column":1},"end":{"line":255,"column":1}},"key":"KcJdZOkO44"}],"key":"ZUpftwMO1M"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":256,"column":1},"end":{"line":267,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":256,"column":1},"end":{"line":257,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"NaNs","position":{"start":{"line":256,"column":1},"end":{"line":256,"column":1}},"key":"dgLgxWGRHn"}],"key":"H6sKsJfRAi"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":257,"column":1},"end":{"line":257,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":257,"column":1},"end":{"line":257,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"SKtime does not work with NaNs","position":{"start":{"line":257,"column":1},"end":{"line":257,"column":1}},"key":"MixFXFxFsW"}],"key":"bp6qBoWG52"}],"key":"cXK06zJz1D"}],"key":"PMgiW54g1q"}],"key":"VDIAym51jW"},{"type":"listItem","spread":true,"position":{"start":{"line":258,"column":1},"end":{"line":259,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"zero flux","position":{"start":{"line":258,"column":1},"end":{"line":258,"column":1}},"key":"ospoV5VfWl"}],"key":"HoS7msCTau"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":259,"column":1},"end":{"line":259,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":259,"column":1},"end":{"line":259,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"there are a few flux measurements that come into our dataframe with zeros.  It is not clear what these are, and zero will be used to mean lack of observation in the rest of this notebook, so want to drop these rows at the outset.","position":{"start":{"line":259,"column":1},"end":{"line":259,"column":1}},"key":"nArWNVatht"}],"key":"rBphw9CCh3"}],"key":"hGrFuUOqBV"}],"key":"oVNNWSJmF6"}],"key":"TnHgedYIxz"},{"type":"listItem","spread":true,"position":{"start":{"line":260,"column":1},"end":{"line":261,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"outliers in uncertainty","position":{"start":{"line":260,"column":1},"end":{"line":260,"column":1}},"key":"ZhM9e6F3Yn"}],"key":"j7HopWaX1S"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":261,"column":1},"end":{"line":261,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":261,"column":1},"end":{"line":261,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"This is a tricky job because we want to keep astrophysical sources that are variable objects, but remove instrumental noise and CR (ground based).  The user will need to choose a sigma clipping threshold, and there is some plotting functionality available to help users make that decision","position":{"start":{"line":261,"column":1},"end":{"line":261,"column":1}},"key":"lbD9h1wknv"}],"key":"xmqAbbVJQA"}],"key":"D0FG3waDW1"}],"key":"MnaJc2vM4I"}],"key":"dp0bFograx"},{"type":"listItem","spread":true,"position":{"start":{"line":262,"column":1},"end":{"line":263,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"objects with no measurements in WISE W1 band","position":{"start":{"line":262,"column":1},"end":{"line":262,"column":1}},"key":"pUN0Qw7tx5"}],"key":"jQIEPNcZvU"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":263,"column":1},"end":{"line":263,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":263,"column":1},"end":{"line":263,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Below we want to normalize all light curves by W1, so we neeed to remove those objects without W1 fluxes because there will be nothing to normalize those light curves with.  We don’t want to have un-normalized data.","position":{"start":{"line":263,"column":1},"end":{"line":263,"column":1}},"key":"pwOHe5UuKc"}],"key":"VDDoCj2WGq"}],"key":"aqGznFMpb0"}],"key":"WpuiZ9fopv"}],"key":"Cs1aqArfuo"},{"type":"listItem","spread":true,"position":{"start":{"line":264,"column":1},"end":{"line":267,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"objects with incomplete data","position":{"start":{"line":264,"column":1},"end":{"line":264,"column":1}},"key":"bQ614tERoQ"}],"key":"yDcBSLpGGv"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":265,"column":1},"end":{"line":267,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":265,"column":1},"end":{"line":267,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Incomplete is defined here as not enough flux measurements to make a good light curve.  Some bands in some objects have only a few datapoints. Three data points is not large enough for KNN interpolation, so we will consider any array with fewer than 4 photometry points to be incomplete data.  Another way of saying this is that we choose to remove those light curves with 3 or\nfewer data points.","position":{"start":{"line":265,"column":1},"end":{"line":265,"column":1}},"key":"fWzWPVHQfM"}],"key":"rfhkecuHdt"}],"key":"sYsZ22tbjb"}],"key":"WijvrQgEvB"}],"key":"Y6aoyi6bt1"}],"key":"e35cHrEesC"}],"key":"oGg3qDmeDy"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#drop rows which have Nans\ndf_lc.dropna(inplace = True, axis = 0)\n\n#drop rows with zero flux\nquerystring = 'flux < 0.000001'\ndf_lc = df_lc.drop(df_lc.query(querystring).index)\n\n#remove outliers\nsigmaclip_value = 10.0\ndf_lc = sigmaclip_lightcurves(df_lc, sigmaclip_value, include_plot = False)\nprint(df_lc.groupby([\"objectid\"]).ngroups, \"n objects after sigma clipping\")\n\n#remove incomplete data\nthreshold_too_few = 3\ndf_lc = remove_incomplete_data(df_lc, threshold_too_few, verbose = False)\n\n#remove objects without W1 fluxes\ndf_lc = remove_objects_without_band(df_lc, 'W1', verbose=True)\n\nprint(df_lc.groupby([\"objectid\"]).ngroups, \"n objects after cleaning the data\")","key":"ilwgeTyU9G"},{"type":"outputs","id":"16NRuVFpuKBOLNJkZIAkA","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"451 n objects after sigma clipping\n"},"key":"d89ABtCc2M"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"18 objects without W1  were removed\n431 n objects after cleaning the data\n"},"key":"ouYCqdKMWt"}],"key":"Xe8sLBQosL"}],"key":"yYY64kaiWt"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":291,"column":1},"end":{"line":291,"column":1}},"children":[{"type":"text","value":"2.5 Missing Data","position":{"start":{"line":291,"column":1},"end":{"line":291,"column":1}},"key":"sXm1pmSU3x"}],"identifier":"id-2-5-missing-data","label":"2.5 Missing Data","html_id":"id-2-5-missing-data","implicit":true,"key":"fJ4EJDCBDV"},{"type":"paragraph","position":{"start":{"line":293,"column":1},"end":{"line":293,"column":1}},"children":[{"type":"text","value":"Some objects do not have light curves in all bands.  Some ML algorithms can handle mising data, but not all, so we try to do something intentional and sensible to handle this missing data up front.","position":{"start":{"line":293,"column":1},"end":{"line":293,"column":1}},"key":"fvtSBstLmn"}],"key":"WWhUa7gypB"},{"type":"paragraph","position":{"start":{"line":295,"column":1},"end":{"line":295,"column":1}},"children":[{"type":"text","value":"There are two options here:","position":{"start":{"line":295,"column":1},"end":{"line":295,"column":1}},"key":"BAF9mGqr2i"}],"key":"wQ9zx5PxYS"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":296,"column":1},"end":{"line":298,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":296,"column":1},"end":{"line":296,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"We will add light curves with zero flux and err values for the missing data.  SKtime does not like NaNs, so we choose zeros.  This option has the benefit of including more bands and therefore more information, but the drawback of having some objects have bands with entire arrays of zeros.","position":{"start":{"line":296,"column":1},"end":{"line":296,"column":1}},"key":"DSkuH0DCcw"}],"key":"gK0voGKG1r"}],"key":"sW1CH5SDw8"},{"type":"listItem","spread":true,"position":{"start":{"line":297,"column":1},"end":{"line":298,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Remove bands which have less data from all objects so that there are no objects with missing data.  This has the benefit of less zeros, but the disadvantage of throwing away some information for the few objects which do have light curves in the bands which will be removed.","position":{"start":{"line":297,"column":1},"end":{"line":297,"column":1}},"key":"DcZd5O3hsh"}],"key":"mJhk0bQFRa"}],"key":"vic7hoJwA7"}],"key":"LRDt9rOnrt"},{"type":"paragraph","position":{"start":{"line":299,"column":1},"end":{"line":299,"column":1}},"children":[{"type":"text","value":"Functions are inlcuded for both options.","position":{"start":{"line":299,"column":1},"end":{"line":299,"column":1}},"key":"zKAp1QfuQz"}],"key":"udQoZqoiHj"}],"key":"NhEAUDErC8"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#choose what to do with missing data...\n#df_lc = missingdata_to_zeros(df_lc)\n#or\nbands_to_keep = ['W1','W2','panstarrs g','panstarrs i', 'panstarrs r','panstarrs y','panstarrs z','zg','zr']\ndf_lc = missingdata_drop_bands(df_lc, bands_to_keep, verbose = True)","key":"ZR7OKjzIFc"},{"type":"outputs","id":"E7xI0QuauFY__Xhq9yND8","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"431 n objects before removing missing band data\n357 n objects after removing missing band data\n"},"key":"CEKGJgbVkK"}],"key":"L3tMmcusci"}],"key":"yQjXHQwuIi"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":309,"column":1},"end":{"line":309,"column":1}},"children":[{"type":"text","value":"2.6  Make all objects and bands have identical time arrays (uniform length and spacing)","position":{"start":{"line":309,"column":1},"end":{"line":309,"column":1}},"key":"bsApwZX7AR"}],"identifier":"id-2-6-make-all-objects-and-bands-have-identical-time-arrays-uniform-length-and-spacing","label":"2.6  Make all objects and bands have identical time arrays (uniform length and spacing)","html_id":"id-2-6-make-all-objects-and-bands-have-identical-time-arrays-uniform-length-and-spacing","implicit":true,"key":"pV2L5NCjIP"},{"type":"paragraph","position":{"start":{"line":311,"column":1},"end":{"line":311,"column":1}},"children":[{"type":"text","value":"It is very hard to find time-domain ML algorithms which can work with non uniform length datasets. Therefore we make the light curves uniform by interpolating using KNN from scikit-learn which fills in the uniform length arrays with a final frequency chosen by the user.  We choose KNN as very straightforward method. This function also shows the framework in case the user wants to choose a different scikit-learn function to do the interpolation.  Another natural choice would be to use gaussian processes (GP) to do the interpolation, but this is not a good solution for our task because the flux values go to zero at times before and after the observations.  Because we include the entire time array from beginning of the first mission to end of the last mission, most individual bands require interpolation before and after their particular observations.  In other words, our light curves span the entire range from 2010 with the start of panstarrs and WISE to the most recent ZTF data release (at least 2023), even though most individual missions do not cover that full range of time.","position":{"start":{"line":311,"column":1},"end":{"line":311,"column":1}},"key":"MkL1Odl5MW"}],"key":"mT2vKBvkai"},{"type":"paragraph","position":{"start":{"line":313,"column":1},"end":{"line":313,"column":1}},"children":[{"type":"text","value":"It is important to choose the frequency over which the data is interpolated wisely.  Experimentation with treating this variable like a hyperparam and testing sktime algorithms shows slightly higher accuracy values for a suite of algorithms for a frequency of one interpolated observation per 60 days.","position":{"start":{"line":313,"column":1},"end":{"line":313,"column":1}},"key":"Mi8rg6QyBv"}],"key":"QT8rA3HDje"}],"key":"JxbnUxdJwd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#what does the dataframe look like at this point in the code?\ndf_lc","key":"NewAIusZn7"},{"type":"outputs","id":"nY_zZqXhadVnTj6idiEKh","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"execute_result","execution_count":12,"metadata":{},"data":{"text/plain":{"content":"        objectid  label         band          time      flux       err\n12489          1  CLAGN  panstarrs i  55174.305492  0.100490  0.001102\n12490          1  CLAGN  panstarrs i  55174.308519  0.090206  0.000985\n12491          1  CLAGN  panstarrs y  55416.614225  0.130497  0.007047\n12492          1  CLAGN  panstarrs y  55416.625133  0.133000  0.006277\n12493          1  CLAGN  panstarrs z  55427.627576  0.118545  0.002673\n...          ...    ...          ...           ...       ...       ...\n412825       458   SDSS           W2  58283.310746  1.793368  0.015925\n412826       458   SDSS           W2  58490.115697  1.630802  0.017747\n412827       458   SDSS           W2  58650.370860  1.674718  0.017944\n412828       458   SDSS           W2  58854.359409  1.475255  0.017491\n412829       458   SDSS           W2  59014.562406  1.400782  0.017341\n\n[346191 rows x 6 columns]","content_type":"text/plain"},"text/html":{"content":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>objectid</th>\n      <th>label</th>\n      <th>band</th>\n      <th>time</th>\n      <th>flux</th>\n      <th>err</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12489</th>\n      <td>1</td>\n      <td>CLAGN</td>\n      <td>panstarrs i</td>\n      <td>55174.305492</td>\n      <td>0.100490</td>\n      <td>0.001102</td>\n    </tr>\n    <tr>\n      <th>12490</th>\n      <td>1</td>\n      <td>CLAGN</td>\n      <td>panstarrs i</td>\n      <td>55174.308519</td>\n      <td>0.090206</td>\n      <td>0.000985</td>\n    </tr>\n    <tr>\n      <th>12491</th>\n      <td>1</td>\n      <td>CLAGN</td>\n      <td>panstarrs y</td>\n      <td>55416.614225</td>\n      <td>0.130497</td>\n      <td>0.007047</td>\n    </tr>\n    <tr>\n      <th>12492</th>\n      <td>1</td>\n      <td>CLAGN</td>\n      <td>panstarrs y</td>\n      <td>55416.625133</td>\n      <td>0.133000</td>\n      <td>0.006277</td>\n    </tr>\n    <tr>\n      <th>12493</th>\n      <td>1</td>\n      <td>CLAGN</td>\n      <td>panstarrs z</td>\n      <td>55427.627576</td>\n      <td>0.118545</td>\n      <td>0.002673</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>412825</th>\n      <td>458</td>\n      <td>SDSS</td>\n      <td>W2</td>\n      <td>58283.310746</td>\n      <td>1.793368</td>\n      <td>0.015925</td>\n    </tr>\n    <tr>\n      <th>412826</th>\n      <td>458</td>\n      <td>SDSS</td>\n      <td>W2</td>\n      <td>58490.115697</td>\n      <td>1.630802</td>\n      <td>0.017747</td>\n    </tr>\n    <tr>\n      <th>412827</th>\n      <td>458</td>\n      <td>SDSS</td>\n      <td>W2</td>\n      <td>58650.370860</td>\n      <td>1.674718</td>\n      <td>0.017944</td>\n    </tr>\n    <tr>\n      <th>412828</th>\n      <td>458</td>\n      <td>SDSS</td>\n      <td>W2</td>\n      <td>58854.359409</td>\n      <td>1.475255</td>\n      <td>0.017491</td>\n    </tr>\n    <tr>\n      <th>412829</th>\n      <td>458</td>\n      <td>SDSS</td>\n      <td>W2</td>\n      <td>59014.562406</td>\n      <td>1.400782</td>\n      <td>0.017341</td>\n    </tr>\n  </tbody>\n</table>\n<p>346191 rows × 6 columns</p>\n</div>","content_type":"text/html"}}},"key":"GcAC5kzx5J"}],"key":"ATfbTfO6EL"}],"key":"v3bbSW5jqh"},{"type":"block","children":[],"key":"UvVj01zzac"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#this cell takes 13seconds to run on the sample of 458 sources\n#change this to change the frequency of the time array\nfinal_freq_interpol = 60  #this is the timescale of interpolation in units of days\n\n#make all light curves have the same time array\ndf_interpol = uniform_length_spacing(df_lc, final_freq_interpol, include_plot = True )\n\n# df_lc_interpol has one row per dict in lc_interpol. time and flux columns store arrays.\n# \"explode\" the dataframe to get one row per light curve point. time and flux columns will now store floats.\ndf_lc = df_interpol.explode([\"time\", \"flux\",\"err\"], ignore_index=True)\ndf_lc = df_lc.astype({col: \"float\" for col in [\"time\", \"flux\", \"err\"]})","key":"neDi6j6v21"},{"type":"outputs","id":"IVLIvmsqRLllek0qcVsAa","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 640x480 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"3b9f553b495948218b80343432817843","path":"/fornax-demo-notebooks/build/3b9f553b495948218b80343432817843.png"}}},"key":"qaYd4hOvJG"}],"key":"KoFF5NUXFS"}],"key":"qBizj9fj14"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":334,"column":1},"end":{"line":334,"column":1}},"children":[{"type":"text","value":"2.7  Restructure dataframe","position":{"start":{"line":334,"column":1},"end":{"line":334,"column":1}},"key":"CDjHIZLOHc"}],"identifier":"id-2-7-restructure-dataframe","label":"2.7  Restructure dataframe","html_id":"id-2-7-restructure-dataframe","implicit":true,"key":"Ajwf0NrhaU"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":336,"column":1},"end":{"line":339,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Make columns have band names in them and then remove band from the index","position":{"start":{"line":336,"column":1},"end":{"line":336,"column":1}},"key":"n2vIWXKRzj"}],"key":"zh4adBeQNY"}],"key":"AdmOyZE0N0"},{"type":"listItem","spread":true,"position":{"start":{"line":337,"column":1},"end":{"line":337,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"pivot the dataframe so that SKTIME understands its format","position":{"start":{"line":337,"column":1},"end":{"line":337,"column":1}},"key":"XjryXDRkty"}],"key":"AI4ZkapuBP"}],"key":"j4dfTCrRUC"},{"type":"listItem","spread":true,"position":{"start":{"line":338,"column":1},"end":{"line":339,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"this will put it in the format expected by sktime","position":{"start":{"line":338,"column":1},"end":{"line":338,"column":1}},"key":"UQPcQo5FjZ"}],"key":"xAfFZVcM4E"}],"key":"J7qgmfvHM6"}],"key":"Fk2bOqC669"}],"key":"WvLlxlceZQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#reformat the data to have columns be the different flux bands\ndf_lc = reformat_df(df_lc)","key":"IGusWPpTpG"},{"type":"outputs","id":"sXtiwfoB96BfpO2_usuST","children":[],"key":"alXwkJ1Hts"}],"key":"mhzpb2VWLx"},{"type":"block","children":[],"key":"BM3nRhFY6n"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#look at a single object to see what this array looks like\nob_of_interest = 12\nsingleob = df_lc[df_lc['objectid'] == ob_of_interest]\nsingleob","key":"ftschFQ1Cs"},{"type":"outputs","id":"xq4g1q_Ncbv2J-n7RDKoK","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"execute_result","execution_count":15,"metadata":{},"data":{"text/plain":{"content":"     objectid  label          time   flux_W1   flux_W2  flux_panstarrs_g  \\\n850        12  CLAGN  54985.275796  0.171426  0.183990          0.014124   \n851        12  CLAGN  55045.275796  0.171426  0.183990          0.014124   \n852        12  CLAGN  55105.275796  0.171426  0.183990          0.014124   \n853        12  CLAGN  55165.275796  0.171426  0.183990          0.014124   \n854        12  CLAGN  55225.275796  0.171426  0.183990          0.014124   \n..        ...    ...           ...       ...       ...               ...   \n930        12  CLAGN  59785.275796  0.193756  0.167459          0.024364   \n931        12  CLAGN  59845.275796  0.193756  0.167459          0.024364   \n932        12  CLAGN  59905.275796  0.193756  0.167459          0.024364   \n933        12  CLAGN  59965.275796  0.193756  0.167459          0.024364   \n934        12  CLAGN  60025.275796  0.193756  0.167459          0.024364   \n\n     flux_panstarrs_i  flux_panstarrs_r  flux_panstarrs_y  flux_panstarrs_z  \\\n850          0.083940          0.043920          0.068864          0.085598   \n851          0.083940          0.043920          0.068864          0.085598   \n852          0.083940          0.043920          0.068864          0.085598   \n853          0.083940          0.043920          0.068864          0.085598   \n854          0.083940          0.043920          0.068864          0.085598   \n..                ...               ...               ...               ...   \n930          0.059121          0.042884          0.097297          0.087929   \n931          0.059121          0.042884          0.097297          0.087929   \n932          0.059121          0.042884          0.097297          0.087929   \n933          0.059121          0.042884          0.097297          0.087929   \n934          0.059121          0.042884          0.097297          0.087929   \n\n     ...   flux_zr    err_W1    err_W2  err_panstarrs_g  err_panstarrs_i  \\\n850  ...  0.065361  0.007365  0.018009          0.00128         0.002069   \n851  ...  0.065361  0.007365  0.018009          0.00128         0.002069   \n852  ...  0.065361  0.007365  0.018009          0.00128         0.002069   \n853  ...  0.065361  0.007365  0.018009          0.00128         0.002069   \n854  ...  0.065361  0.007365  0.018009          0.00128         0.002069   \n..   ...       ...       ...       ...              ...              ...   \n930  ...  0.057135  0.007365  0.018009          0.00128         0.002069   \n931  ...  0.061469  0.007365  0.018009          0.00128         0.002069   \n932  ...  0.064667  0.007365  0.018009          0.00128         0.002069   \n933  ...  0.063702  0.007365  0.018009          0.00128         0.002069   \n934  ...  0.063702  0.007365  0.018009          0.00128         0.002069   \n\n     err_panstarrs_r  err_panstarrs_y  err_panstarrs_z    err_zg   err_zr  \n850         0.002013         0.007337            0.004  0.003695  0.00521  \n851         0.002013         0.007337            0.004  0.003695  0.00521  \n852         0.002013         0.007337            0.004  0.003695  0.00521  \n853         0.002013         0.007337            0.004  0.003695  0.00521  \n854         0.002013         0.007337            0.004  0.003695  0.00521  \n..               ...              ...              ...       ...      ...  \n930         0.002013         0.007337            0.004  0.003695  0.00521  \n931         0.002013         0.007337            0.004  0.003695  0.00521  \n932         0.002013         0.007337            0.004  0.003695  0.00521  \n933         0.002013         0.007337            0.004  0.003695  0.00521  \n934         0.002013         0.007337            0.004  0.003695  0.00521  \n\n[85 rows x 21 columns]","content_type":"text/plain"},"text/html":{"content":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>objectid</th>\n      <th>label</th>\n      <th>time</th>\n      <th>flux_W1</th>\n      <th>flux_W2</th>\n      <th>flux_panstarrs_g</th>\n      <th>flux_panstarrs_i</th>\n      <th>flux_panstarrs_r</th>\n      <th>flux_panstarrs_y</th>\n      <th>flux_panstarrs_z</th>\n      <th>...</th>\n      <th>flux_zr</th>\n      <th>err_W1</th>\n      <th>err_W2</th>\n      <th>err_panstarrs_g</th>\n      <th>err_panstarrs_i</th>\n      <th>err_panstarrs_r</th>\n      <th>err_panstarrs_y</th>\n      <th>err_panstarrs_z</th>\n      <th>err_zg</th>\n      <th>err_zr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>850</th>\n      <td>12</td>\n      <td>CLAGN</td>\n      <td>54985.275796</td>\n      <td>0.171426</td>\n      <td>0.183990</td>\n      <td>0.014124</td>\n      <td>0.083940</td>\n      <td>0.043920</td>\n      <td>0.068864</td>\n      <td>0.085598</td>\n      <td>...</td>\n      <td>0.065361</td>\n      <td>0.007365</td>\n      <td>0.018009</td>\n      <td>0.00128</td>\n      <td>0.002069</td>\n      <td>0.002013</td>\n      <td>0.007337</td>\n      <td>0.004</td>\n      <td>0.003695</td>\n      <td>0.00521</td>\n    </tr>\n    <tr>\n      <th>851</th>\n      <td>12</td>\n      <td>CLAGN</td>\n      <td>55045.275796</td>\n      <td>0.171426</td>\n      <td>0.183990</td>\n      <td>0.014124</td>\n      <td>0.083940</td>\n      <td>0.043920</td>\n      <td>0.068864</td>\n      <td>0.085598</td>\n      <td>...</td>\n      <td>0.065361</td>\n      <td>0.007365</td>\n      <td>0.018009</td>\n      <td>0.00128</td>\n      <td>0.002069</td>\n      <td>0.002013</td>\n      <td>0.007337</td>\n      <td>0.004</td>\n      <td>0.003695</td>\n      <td>0.00521</td>\n    </tr>\n    <tr>\n      <th>852</th>\n      <td>12</td>\n      <td>CLAGN</td>\n      <td>55105.275796</td>\n      <td>0.171426</td>\n      <td>0.183990</td>\n      <td>0.014124</td>\n      <td>0.083940</td>\n      <td>0.043920</td>\n      <td>0.068864</td>\n      <td>0.085598</td>\n      <td>...</td>\n      <td>0.065361</td>\n      <td>0.007365</td>\n      <td>0.018009</td>\n      <td>0.00128</td>\n      <td>0.002069</td>\n      <td>0.002013</td>\n      <td>0.007337</td>\n      <td>0.004</td>\n      <td>0.003695</td>\n      <td>0.00521</td>\n    </tr>\n    <tr>\n      <th>853</th>\n      <td>12</td>\n      <td>CLAGN</td>\n      <td>55165.275796</td>\n      <td>0.171426</td>\n      <td>0.183990</td>\n      <td>0.014124</td>\n      <td>0.083940</td>\n      <td>0.043920</td>\n      <td>0.068864</td>\n      <td>0.085598</td>\n      <td>...</td>\n      <td>0.065361</td>\n      <td>0.007365</td>\n      <td>0.018009</td>\n      <td>0.00128</td>\n      <td>0.002069</td>\n      <td>0.002013</td>\n      <td>0.007337</td>\n      <td>0.004</td>\n      <td>0.003695</td>\n      <td>0.00521</td>\n    </tr>\n    <tr>\n      <th>854</th>\n      <td>12</td>\n      <td>CLAGN</td>\n      <td>55225.275796</td>\n      <td>0.171426</td>\n      <td>0.183990</td>\n      <td>0.014124</td>\n      <td>0.083940</td>\n      <td>0.043920</td>\n      <td>0.068864</td>\n      <td>0.085598</td>\n      <td>...</td>\n      <td>0.065361</td>\n      <td>0.007365</td>\n      <td>0.018009</td>\n      <td>0.00128</td>\n      <td>0.002069</td>\n      <td>0.002013</td>\n      <td>0.007337</td>\n      <td>0.004</td>\n      <td>0.003695</td>\n      <td>0.00521</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>930</th>\n      <td>12</td>\n      <td>CLAGN</td>\n      <td>59785.275796</td>\n      <td>0.193756</td>\n      <td>0.167459</td>\n      <td>0.024364</td>\n      <td>0.059121</td>\n      <td>0.042884</td>\n      <td>0.097297</td>\n      <td>0.087929</td>\n      <td>...</td>\n      <td>0.057135</td>\n      <td>0.007365</td>\n      <td>0.018009</td>\n      <td>0.00128</td>\n      <td>0.002069</td>\n      <td>0.002013</td>\n      <td>0.007337</td>\n      <td>0.004</td>\n      <td>0.003695</td>\n      <td>0.00521</td>\n    </tr>\n    <tr>\n      <th>931</th>\n      <td>12</td>\n      <td>CLAGN</td>\n      <td>59845.275796</td>\n      <td>0.193756</td>\n      <td>0.167459</td>\n      <td>0.024364</td>\n      <td>0.059121</td>\n      <td>0.042884</td>\n      <td>0.097297</td>\n      <td>0.087929</td>\n      <td>...</td>\n      <td>0.061469</td>\n      <td>0.007365</td>\n      <td>0.018009</td>\n      <td>0.00128</td>\n      <td>0.002069</td>\n      <td>0.002013</td>\n      <td>0.007337</td>\n      <td>0.004</td>\n      <td>0.003695</td>\n      <td>0.00521</td>\n    </tr>\n    <tr>\n      <th>932</th>\n      <td>12</td>\n      <td>CLAGN</td>\n      <td>59905.275796</td>\n      <td>0.193756</td>\n      <td>0.167459</td>\n      <td>0.024364</td>\n      <td>0.059121</td>\n      <td>0.042884</td>\n      <td>0.097297</td>\n      <td>0.087929</td>\n      <td>...</td>\n      <td>0.064667</td>\n      <td>0.007365</td>\n      <td>0.018009</td>\n      <td>0.00128</td>\n      <td>0.002069</td>\n      <td>0.002013</td>\n      <td>0.007337</td>\n      <td>0.004</td>\n      <td>0.003695</td>\n      <td>0.00521</td>\n    </tr>\n    <tr>\n      <th>933</th>\n      <td>12</td>\n      <td>CLAGN</td>\n      <td>59965.275796</td>\n      <td>0.193756</td>\n      <td>0.167459</td>\n      <td>0.024364</td>\n      <td>0.059121</td>\n      <td>0.042884</td>\n      <td>0.097297</td>\n      <td>0.087929</td>\n      <td>...</td>\n      <td>0.063702</td>\n      <td>0.007365</td>\n      <td>0.018009</td>\n      <td>0.00128</td>\n      <td>0.002069</td>\n      <td>0.002013</td>\n      <td>0.007337</td>\n      <td>0.004</td>\n      <td>0.003695</td>\n      <td>0.00521</td>\n    </tr>\n    <tr>\n      <th>934</th>\n      <td>12</td>\n      <td>CLAGN</td>\n      <td>60025.275796</td>\n      <td>0.193756</td>\n      <td>0.167459</td>\n      <td>0.024364</td>\n      <td>0.059121</td>\n      <td>0.042884</td>\n      <td>0.097297</td>\n      <td>0.087929</td>\n      <td>...</td>\n      <td>0.063702</td>\n      <td>0.007365</td>\n      <td>0.018009</td>\n      <td>0.00128</td>\n      <td>0.002069</td>\n      <td>0.002013</td>\n      <td>0.007337</td>\n      <td>0.004</td>\n      <td>0.003695</td>\n      <td>0.00521</td>\n    </tr>\n  </tbody>\n</table>\n<p>85 rows × 21 columns</p>\n</div>","content_type":"text/html"}}},"key":"aSi5ihH2bQ"}],"key":"h06f7VrNfE"}],"key":"pllTuefy9W"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":352,"column":1},"end":{"line":352,"column":1}},"children":[{"type":"text","value":"2.8 Normalize","position":{"start":{"line":352,"column":1},"end":{"line":352,"column":1}},"key":"Ix3ZTD0zvc"}],"identifier":"id-2-8-normalize","label":"2.8 Normalize","html_id":"id-2-8-normalize","implicit":true,"key":"uRegHBjwl5"},{"type":"paragraph","position":{"start":{"line":354,"column":1},"end":{"line":354,"column":1}},"children":[{"type":"text","value":"Normalizing is required so that the CLAGN and it’s comparison SDSS sample don’t have different flux levels.  ML algorithms will easily choose to classify based on overall flux levels, so we want to prevent that by normalizing the fluxes. Normalization with a multiband dataset requires extra thought.  The idea here is that we normalize across each object.  We want the algorithms to know, for example, that within one object W1 will be brighter than ZTF bands but from one object to the next, it will not know that one is brighter than the other.","position":{"start":{"line":354,"column":1},"end":{"line":354,"column":1}},"key":"UKubVfrsCD"}],"key":"eqiLZjA2ad"},{"type":"paragraph","position":{"start":{"line":356,"column":1},"end":{"line":356,"column":1}},"children":[{"type":"text","value":"We do the normalization at this point in the code, rather than before interpolating over time, so that the final light curves are normalized since that is the chunk of information which goes into the ML algorithms.","position":{"start":{"line":356,"column":1},"end":{"line":356,"column":1}},"key":"bIazkwfIc7"}],"key":"AE5bvQ8aV2"},{"type":"paragraph","position":{"start":{"line":358,"column":1},"end":{"line":358,"column":1}},"children":[{"type":"text","value":"We chose to normalize by the maximum flux in one band, and not median or mean because there are some objects where the median flux = 0.0 if we did a replacement by zeros for missing data.","position":{"start":{"line":358,"column":1},"end":{"line":358,"column":1}},"key":"ccvLAo5se3"}],"key":"rM9jfCB6Jh"}],"key":"e9dycyqJHc"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#normalize by W1 band\ndf_lc = local_normalization_max(df_lc, norm_column = \"flux_W1\")","key":"uia54xp33l"},{"type":"outputs","id":"oXOoPRGvGMoC8PXfJAMXz","children":[],"key":"LjRSsdSKwT"}],"key":"KT8xpTvIEM"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":365,"column":1},"end":{"line":365,"column":1}},"children":[{"type":"text","value":"2.9 Cleanup","position":{"start":{"line":365,"column":1},"end":{"line":365,"column":1}},"key":"UgSYzgZPSD"}],"identifier":"id-2-9-cleanup","label":"2.9 Cleanup","html_id":"id-2-9-cleanup","implicit":true,"key":"vvtvzhVuqs"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":367,"column":1},"end":{"line":370,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":367,"column":1},"end":{"line":368,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Make ","position":{"start":{"line":367,"column":1},"end":{"line":367,"column":1}},"key":"MnQbWIYviy"},{"type":"link","url":"https://docs.python.org/3/library/datetime.html#module-datetime","position":{"start":{"line":367,"column":1},"end":{"line":367,"column":1}},"children":[{"type":"text","value":"datetime","position":{"start":{"line":367,"column":1},"end":{"line":367,"column":1}},"key":"hc7Cb6CFSI"}],"urlSource":"https://docs.python.org/3/library/datetime.html#module-datetime","key":"G6jaSC0fYv"},{"type":"text","value":" column","position":{"start":{"line":367,"column":1},"end":{"line":367,"column":1}},"key":"C6fGJ4rRK9"}],"key":"yqFbkSf0NP"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":368,"column":1},"end":{"line":368,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":368,"column":1},"end":{"line":368,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"SKTime wants a datetime column","position":{"start":{"line":368,"column":1},"end":{"line":368,"column":1}},"key":"hx671zTtnB"}],"key":"CWiJAtKq4a"}],"key":"MdPL3sXTi5"}],"key":"yoiguxauKc"}],"key":"hPIgD6mq8r"},{"type":"listItem","spread":true,"position":{"start":{"line":369,"column":1},"end":{"line":370,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Save dataframe","position":{"start":{"line":369,"column":1},"end":{"line":369,"column":1}},"key":"lnzhiXOpef"}],"key":"r9tR0UY7MN"}],"key":"KiOAZ0Wj3n"}],"key":"cB6auuwsoc"}],"key":"nmFfmbZyIh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# need to make a datetime column\ndf_lc['datetime'] = mjd_to_datetime(df_lc)","key":"Y48SpbR4Pm"},{"type":"outputs","id":"t2MzvffqkIYbqz4hPJ9_y","children":[],"key":"OivACyz0iY"}],"key":"GacPl2zMEP"},{"type":"block","children":[],"key":"JlyVfImW93"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#save this dataframe to use for the ML below so we don't have to make it every time\nparquet_savename = 'output/df_lc_ML.parquet'\n#df_lc.to_parquet(parquet_savename)\n#print(\"file saved!\")","key":"AUj7xZKdlQ"},{"type":"outputs","id":"GNEV74LqxdquSF00wEOFj","children":[],"key":"jOpSj9gaSh"}],"key":"PFkZaucZHt"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":383,"column":1},"end":{"line":383,"column":1}},"children":[{"type":"text","value":"3. Prep for ML algorithms","position":{"start":{"line":383,"column":1},"end":{"line":383,"column":1}},"key":"z1MLycKlw6"}],"identifier":"id-3-prep-for-ml-algorithms","label":"3. Prep for ML algorithms","html_id":"id-3-prep-for-ml-algorithms","implicit":true,"key":"fo08wxrERT"}],"key":"WjnUC9Blfk"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# could load a previously saved file in order to plot\n#parquet_loadname = 'output/df_lc_ML.parquet'\n#df_lc = MultiIndexDFObject()\n#df_lc.data = pd.read_parquet(parquet_loadname)\n#print(\"file loaded!\")","key":"HRF5vMqRGN"},{"type":"outputs","id":"m2mRwS_GVdoQc2capd0Cc","children":[],"key":"M9rQueW7Bv"}],"key":"nGJn22vNiN"},{"type":"block","children":[],"key":"AnzNF52zAn"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#try dropping the uncertainty columns as variables for sktime\ndf_lc.drop(columns = ['err_panstarrs_g',\t'err_panstarrs_i',\t'err_panstarrs_r',\t'err_panstarrs_y',\n                      'err_panstarrs_z',\t'err_W1',\t'err_W2',\t'err_zg',\t'err_zr'], inplace = True)\n\n#drop also the time column because time shouldn't be a feature\ndf_lc.drop(columns = ['time'],inplace = True)","key":"yonjwgv9ST"},{"type":"outputs","id":"I1F4bJ2RLaal9cJE59ZBR","children":[],"key":"UDSN2pKA5G"}],"key":"tQr55elFDb"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":402,"column":1},"end":{"line":402,"column":1}},"children":[{"type":"text","value":"3.1 Train test split","position":{"start":{"line":402,"column":1},"end":{"line":402,"column":1}},"key":"QnbY78r155"}],"identifier":"id-3-1-train-test-split","label":"3.1 Train test split","html_id":"id-3-1-train-test-split","implicit":true,"key":"IYKirMxZbO"},{"type":"paragraph","position":{"start":{"line":404,"column":1},"end":{"line":404,"column":1}},"children":[{"type":"text","value":"We use sklearn’s train test split to randomly split the data into training and testing datasets.  Because thre are uneven numbers of each type (many more SDSS than CLAGN), we want to make sure to stratify evenly by type.","position":{"start":{"line":404,"column":1},"end":{"line":404,"column":1}},"key":"mEFhJfX4V8"}],"key":"jZMMYYL1j0"}],"key":"EFr4k5nwtD"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#divide the dataframe into features and labels for ML algorithms\nlabels = df_lc[[\"objectid\", \"label\"]].drop_duplicates().set_index(\"objectid\").label\ndf_lc = df_lc.drop(columns=[\"label\"]).set_index([\"objectid\", \"datetime\"])","key":"ubOpoi7eZD"},{"type":"outputs","id":"BjDfEJuRN3KnvOgtzBTdh","children":[],"key":"dlwuIFgFpK"}],"key":"hkUaf6bkVt"},{"type":"block","children":[],"key":"PCYxorF1Lq"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"test_size = 0.25\n\n#want a stratified split based on label\ntrain_ix, test_ix = train_test_split(df_lc.index.levels[0], stratify = labels, shuffle = True, random_state = 43, test_size = test_size)\n\n#X is defined to be the features\n#y is defined to be the labels\nX_train = df_lc.loc[train_ix]\ny_train = labels.loc[train_ix]\nX_test = df_lc.loc[test_ix]\ny_test = labels.loc[test_ix]\n\n#plot to show how many of each type of object in the test dataset\nplt.figure(figsize=(6,4))\nplt.title(\"Objects in the Test dataset\")\nh = plt.hist(y_test, histtype='stepfilled', orientation='horizontal')","key":"hdFkfImpC4"},{"type":"outputs","id":"mA-g1HMnSmPXlQp1yfJzl","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 600x400 with 1 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"9302fd2d424f2699a0ab9dc136ba8efa","path":"/fornax-demo-notebooks/build/9302fd2d424f2699a0ab9dc136ba8efa.png"}}},"key":"xpaOcoWliF"}],"key":"i12msH3IIl"}],"key":"H7M1SgRFNu"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":431,"column":1},"end":{"line":431,"column":1}},"children":[{"type":"text","value":"4. Run sktime algorithms on the light curves","position":{"start":{"line":431,"column":1},"end":{"line":431,"column":1}},"key":"RwSw9S1PTc"}],"identifier":"id-4-run-sktime-algorithms-on-the-light-curves","label":"4. Run sktime algorithms on the light curves","html_id":"id-4-run-sktime-algorithms-on-the-light-curves","implicit":true,"key":"roxQIdCkcg"},{"type":"paragraph","position":{"start":{"line":433,"column":1},"end":{"line":433,"column":1}},"children":[{"type":"text","value":"We choose to use ","position":{"start":{"line":433,"column":1},"end":{"line":433,"column":1}},"key":"DE6aPJsITV"},{"type":"link","url":"https://www.sktime.net/en/stable/index.html","position":{"start":{"line":433,"column":1},"end":{"line":433,"column":1}},"children":[{"type":"text","value":"sktime","position":{"start":{"line":433,"column":1},"end":{"line":433,"column":1}},"key":"onQ2fTI4oR"}],"urlSource":"https://www.sktime.net/en/stable/index.html","key":"FEXy5XsLWw"},{"type":"text","value":" algorithms beacuse it is a library of many algorithms specifically tailored to time series datasets.  It is based on the sklearn library so syntax is familiar to many users.","position":{"start":{"line":433,"column":1},"end":{"line":433,"column":1}},"key":"ZYsFBA3LoP"}],"key":"UNtQ70Hqix"},{"type":"paragraph","position":{"start":{"line":435,"column":1},"end":{"line":435,"column":1}},"children":[{"type":"text","value":"Types of classifiers are listed ","position":{"start":{"line":435,"column":1},"end":{"line":435,"column":1}},"key":"OEV1yO3EFs"},{"type":"link","url":"https://www.sktime.net/en/stable/api_reference/classification.html","position":{"start":{"line":435,"column":1},"end":{"line":435,"column":1}},"children":[{"type":"text","value":"here","position":{"start":{"line":435,"column":1},"end":{"line":435,"column":1}},"key":"lVSnrthGQH"}],"urlSource":"https://www.sktime.net/en/stable/api_reference/classification.html","key":"Ea62HHic2H"},{"type":"text","value":".","position":{"start":{"line":435,"column":1},"end":{"line":435,"column":1}},"key":"SEe62fEmmF"}],"key":"HaarZVVhxs"},{"type":"paragraph","position":{"start":{"line":437,"column":1},"end":{"line":437,"column":1}},"children":[{"type":"text","value":"This notebook will first show you an example of a single algorithm classifier. Then it will show how to write a for loop over a bunch of classifiers while outputting some metrics of accuracy.","position":{"start":{"line":437,"column":1},"end":{"line":437,"column":1}},"key":"F9DPa3pryA"}],"key":"dVkpusWbEY"}],"key":"BnVpcGmhsZ"},{"type":"block","position":{"start":{"line":439,"column":1},"end":{"line":439,"column":1}},"children":[{"type":"heading","depth":3,"position":{"start":{"line":441,"column":1},"end":{"line":441,"column":1}},"children":[{"type":"text","value":"4.1 Check that the data types are ok for sktime","position":{"start":{"line":441,"column":1},"end":{"line":441,"column":1}},"key":"eIZhUhoFX7"}],"identifier":"id-4-1-check-that-the-data-types-are-ok-for-sktime","label":"4.1 Check that the data types are ok for sktime","html_id":"id-4-1-check-that-the-data-types-are-ok-for-sktime","implicit":true,"key":"iD1sL2fjjI"},{"type":"paragraph","position":{"start":{"line":443,"column":1},"end":{"line":443,"column":1}},"children":[{"type":"text","value":"This test needs to pass in order for sktime to run","position":{"start":{"line":443,"column":1},"end":{"line":443,"column":1}},"key":"vqlJX75qKJ"}],"key":"dMo4MBkZc6"}],"key":"fgNGAS5LVh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#ask sktime if it likes the data type of X_train\n#if you change any of the functions or cells above this one, it is a good idea to\n# look at the below output to make sure you haven't introduced any NaNs or unequal length series\ncheck_is_mtype(X_train, mtype=\"pd-multiindex\", scitype=\"Panel\", return_metadata=True)","key":"sdb4fEWcMY"},{"type":"outputs","id":"4crvCduiskarrrHXeg6R_","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"execute_result","execution_count":23,"metadata":{},"data":{"text/plain":{"content":"(True,\n '',\n {'is_univariate': False,\n  'is_empty': False,\n  'has_nans': np.False_,\n  'n_features': 9,\n  'feature_names': ['flux_W1',\n   'flux_W2',\n   'flux_panstarrs_g',\n   'flux_panstarrs_i',\n   'flux_panstarrs_r',\n   'flux_panstarrs_y',\n   'flux_panstarrs_z',\n   'flux_zg',\n   'flux_zr'],\n  'dtypekind_dfip': [<DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>],\n  'feature_kind': [<DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>,\n   <DtypeKind.FLOAT: 2>],\n  'n_instances': 267,\n  'is_one_series': False,\n  'is_equal_length': np.True_,\n  'is_equally_spaced': True,\n  'n_panels': 1,\n  'is_one_panel': True,\n  'mtype': 'pd-multiindex',\n  'scitype': 'Panel'})","content_type":"text/plain"}}},"key":"OYDDhlaCE2"}],"key":"DWduPd1HiN"}],"key":"LFFrBtjqU3"},{"type":"block","children":[],"key":"dnpEwo3w01"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#show the list of all possible classifiers that work with multivariate data\n#all_tags(estimator_types = 'classifier')\n#classifiers = all_estimators(\"classifier\", filter_tags={'capability:multivariate':True})\n#classifiers","key":"ZBIMiYD50p"},{"type":"outputs","id":"hxGggc8NwSWJ_BIQkyk9m","children":[],"key":"C5630l31jw"}],"key":"dpnIF7xiFU"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":459,"column":1},"end":{"line":459,"column":1}},"children":[{"type":"text","value":"4.2 A single Classifier","position":{"start":{"line":459,"column":1},"end":{"line":459,"column":1}},"key":"AQLz6mp7q9"}],"identifier":"id-4-2-a-single-classifier","label":"4.2 A single Classifier","html_id":"id-4-2-a-single-classifier","implicit":true,"key":"iuYGnGk4WS"}],"key":"wXhrnAk2Ky"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#this cell takes 35s to run on a sample of 267 light curves\n\n#setup the classifier\n#n_jobs is the number of jobs to run in parallel. some environments have trouble with this.\n#if you encounter an error such as 'BrokenProcessPool' while training or predicting, you may\n#want to either set n_jobs = 1 or use a different compute environment.\nclf = Arsenal(time_limit_in_minutes=1, n_jobs = -1)  # '-1' n_jobs means use all processors\n\n#fit the classifier on the training dataset\nclf.fit(X_train, y_train)\n\n#make predictions on the test dataset using the trained model\ny_pred = clf.predict(X_test)\n\nprint(f\"Accuracy of Random Interval Classifier: {accuracy_score(y_test, y_pred)}\\n\", flush=True)\n\n#plot a confusion matrix\ncm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=clf.classes_)\ndisp.plot()\n\nplt.show()","key":"iskveEYCTR"},{"type":"outputs","id":"dLcVEakDE9TlXSTdvDyaK","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Accuracy of Random Interval Classifier: 0.7111111111111111\n\n"},"key":"EcyqCOlj5c"},{"type":"output","children":[],"jupyter_data":{"output_type":"display_data","metadata":{},"data":{"text/plain":{"content":"<Figure size 640x480 with 2 Axes>","content_type":"text/plain"},"image/png":{"content_type":"image/png","hash":"08aa62893423e3d0e5d8025064fe350e","path":"/fornax-demo-notebooks/build/08aa62893423e3d0e5d8025064fe350e.png"}}},"key":"cps7ER4JXp"}],"key":"cgDv1qQd8E"}],"key":"qg1znINxH7"},{"type":"block","children":[{"type":"heading","depth":3,"position":{"start":{"line":486,"column":1},"end":{"line":486,"column":1}},"children":[{"type":"text","value":"4.3 Loop over a bunch of classifiers","position":{"start":{"line":486,"column":1},"end":{"line":486,"column":1}},"key":"GTccGc2SwN"}],"identifier":"id-4-3-loop-over-a-bunch-of-classifiers","label":"4.3 Loop over a bunch of classifiers","html_id":"id-4-3-loop-over-a-bunch-of-classifiers","implicit":true,"key":"fTErHN7yDq"},{"type":"paragraph","position":{"start":{"line":488,"column":1},"end":{"line":488,"column":1}},"children":[{"type":"text","value":"Our method is to do a cursory check of a bunch of classifiers and then later drill down deeper on anything with good initial results.  We choose to run a loop over ~10 classifiers that seem promising and check the accuracy scores for each one.  Any classifier with a promising accuracy score could then be followed up with detailed hyperparameter tuning, or potentially with considering other classifiers in that same type.","position":{"start":{"line":488,"column":1},"end":{"line":488,"column":1}},"key":"NDc7k4vA2D"}],"key":"HJUgPeG6nt"},{"type":"mystDirective","name":"raw-cell","value":"#This cell is currently not being run because it takes a long time\n\n#which classifiers are we interestd in\n#roughly one from each type of classifier\n\nnames = [\"Arsenal\",                     #kernel based\n        \"RocektClassifier\",             #kernel based\n        \"CanonicalIntervalForest\",      #interval based\n        \"HIVECOTEV2\",                   #hybrid\n#        \"CNNClassifier\",               #Deep Learning  - **requires tensorflow which is giving import errors\n#        \"WeightedEnsembleClassifier\",   #Ensemble - **maybe use in the future if we find good options\n        \"IndividualTDE\",               #Dictionary-based\n        \"KNeighborsTimeSeriesClassifier\", #Distance Based\n        \"RandomIntervalClassifier\",     #Feature based\n        \"Catch22Classifier\",            #Feature based\n        \"ShapeletTransformClassifier\"   #Shapelet based\n        \"DummyClassifier\"]             #Dummy - ignores input\n\n#for those with an impossible time limit, how long to let them run for before cutting off\nnmins = 3\n\n#these could certainly be more tailored\nclassifier_call = [Arsenal(time_limit_in_minutes=nmins, n_jobs = -1),\n                  RocketClassifier(num_kernels=2000),\n                  CanonicalIntervalForest(n_jobs = -1),\n                  HIVECOTEV2(time_limit_in_minutes=nmins, n_jobs = -1),\n#                  CNNClassifier(),\n#                  WeightedEnsembleClassifier(),\n                  IndividualTDE(n_jobs=-1),\n                  KNeighborsTimeSeriesClassifier(n_jobs = -1),\n                  RandomIntervalClassifier(n_intervals = 20, n_jobs = -1, random_state = 43),\n                  Catch22Classifier(outlier_norm = True, n_jobs = -1, random_state = 43),\n                  ShapeletTransformClassifier(time_limit_in_minutes=nmins,n_jobs = -1),\n                  DummyClassifier()]\n\n#setup to store the accuracy scores\naccscore_dict = {}\n\n# iterate over classifiers\nfor name, clf in tqdm(zip(names, classifier_call)):\n    #fit the classifier\n    clf.fit(X_train, y_train)\n\n    #make predictions on the test dataset\n    y_pred = clf.predict(X_test)\n\n    #calculate and track accuracy score\n    accscore = accuracy_score(y_test, y_pred)\n    print(f\"Accuracy of {name} classifier: {accscore}\\n\", flush=True)\n    accscore_dict[name] = accscore\n\n    #plot confusion matrix\n    cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=clf.classes_)\n    disp.plot()\n    plt.show()","position":{"start":{"line":490,"column":1},"end":{"line":547,"column":1}},"key":"Cv9w3v7xdH"}],"key":"V1EoxPVn55"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#show the summary of the algorithms used and their accuracy score\n#accscore_dict","key":"BHq9vIaOIL"},{"type":"outputs","id":"qZnEZJ1LSl3KY5e2kxH9z","children":[],"key":"afXUAvCoRW"}],"key":"f2mUcXWw5z"},{"type":"block","children":[],"key":"EZa1jOIs0E"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#save statistics from these runs\n\n# Serialize data into file:\n#json.dump( accscore_dict, open( \"output/accscore.json\", 'w' ) )\n#json.dump( completeness_dict, open( \"output/completeness.json\", 'w' ) )\n#json.dump( homogeneity_dict, open( \"output/homogeneity.json\", 'w' ) )\n\n# Read data from file:\n#accscore_dict = json.load( open( \"output/accscore.json\") )","key":"ejBDjoMHXK"},{"type":"outputs","id":"091OGevVxQfx8aDQpuhJP","children":[],"key":"J0ouWdeUxz"}],"key":"WaeNyRZs3U"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":566,"column":1},"end":{"line":566,"column":1}},"children":[{"type":"text","value":"5. Create a candidate list","position":{"start":{"line":566,"column":1},"end":{"line":566,"column":1}},"key":"TiARWRBzKq"}],"identifier":"id-5-create-a-candidate-list","label":"5. Create a candidate list","html_id":"id-5-create-a-candidate-list","implicit":true,"key":"eaUsw5usME"},{"type":"paragraph","position":{"start":{"line":568,"column":1},"end":{"line":568,"column":1}},"children":[{"type":"text","value":"Lets assume we now have a classifier which can accurately differentiate CLAGN from SDSS QSOs based on their archival light curves.  Next, we would like to use that classifier on our favorite unlabeled sample to identify CLAGN candidates.  To do this, we need to:","position":{"start":{"line":568,"column":1},"end":{"line":568,"column":1}},"key":"Nqnl1rkZXW"}],"key":"a9VSu1SKqJ"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":569,"column":1},"end":{"line":574,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":569,"column":1},"end":{"line":569,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"read in a dataframe of our new sample","position":{"start":{"line":569,"column":1},"end":{"line":569,"column":1}},"key":"aOB9hlQ6vy"}],"key":"PI3Hy9OfUY"}],"key":"IS6WR5vhSa"},{"type":"listItem","spread":true,"position":{"start":{"line":570,"column":1},"end":{"line":570,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"get that dataset in the same format as what was fed into the classifiers","position":{"start":{"line":570,"column":1},"end":{"line":570,"column":1}},"key":"vPirzrMi8o"}],"key":"uGY7j4bSBg"}],"key":"wrtgT1CZq7"},{"type":"listItem","spread":true,"position":{"start":{"line":571,"column":1},"end":{"line":571,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"use your trained classifier to predict labels for the new sample","position":{"start":{"line":571,"column":1},"end":{"line":571,"column":1}},"key":"fORBqT3GLi"}],"key":"KL1tvIETyU"}],"key":"spow7WVoJ7"},{"type":"listItem","spread":true,"position":{"start":{"line":572,"column":1},"end":{"line":572,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"retrace those objectids to an ra & dec","position":{"start":{"line":572,"column":1},"end":{"line":572,"column":1}},"key":"RCdDsMl6TN"}],"key":"X09Cfyrig5"}],"key":"cQMSDa1JpF"},{"type":"listItem","spread":true,"position":{"start":{"line":573,"column":1},"end":{"line":574,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"write an observing proposal (ok, you have to do that one yourself)","position":{"start":{"line":573,"column":1},"end":{"line":573,"column":1}},"key":"X8zM0QMbVd"}],"key":"QxG94F8XQl"}],"key":"LvjkmqxygN"}],"key":"cAsBQsQAII"}],"key":"qSRQDMNMZx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#read in a dataframe of our new sample:\n# we are going to cheat here and use the same file as we used for input to the above, but you should\n# replace this with your favorite sample run through the light_curve_collector in this same repo.\npath_to_sample = './data/small_CLAGN_SDSS_df_lc.parquet'\nmy_sample = pd.read_parquet(path_to_sample)","key":"xePsyXLoJn"},{"type":"outputs","id":"oaLRGVB47KobTMBchHN1V","children":[],"key":"gEyaoqAwEG"}],"key":"IhpOPNe2Sz"},{"type":"block","children":[],"key":"LsFV2D5sDc"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#get dataset in same format as what was run through sktime\n#This is not exactly the same as re-running the whole notebook on a different sample,\n#but it is pretty close.  We don't need to do all of the same cleaning because some of that\n#was to appease sktime in training the algorithms.\n\n\n#get rid of indices set in the light curve code and reset them as needed before sktime algorithms\nmy_sample = my_sample.reset_index()\n\n# get rid of some of the bands that don't have enough data for all the sources\n#CLAGN are generall fainter targets, and therefore mostly not found in datasets like TESS & K2\n#make sure your sample has the same bands as were run to train the classifier\nmy_sample = my_sample[~my_sample[\"band\"].isin(bands_to_drop)]\n\n#drop rows which have Nans\nmy_sample.dropna(inplace = True, axis = 0)\n\n#remove outliers\n#make sure your sample has the same sigmaclip_value as was run to train the classifier\nmy_sample = sigmaclip_lightcurves(my_sample, sigmaclip_value, include_plot = False, verbose= False)\n\n#remove objects without W1 fluxes\nmy_sample = remove_objects_without_band(my_sample, 'W1', verbose=False)\n\n#remove incomplete data\n#make sure your sample has the same threshold_too_few as were run to train the classifier\nmy_sample = remove_incomplete_data(my_sample, threshold_too_few, verbose = False)\n\n#drop missing bands\nmy_sample = missingdata_drop_bands(my_sample, bands_to_keep, verbose = False)\n\n#make arrays have uniform length and spacing\n#make sure your sample has the same final_feq_interpol as was run to train the classifier\ndf_interpol = uniform_length_spacing(my_sample, final_freq_interpol, include_plot = False )\nmy_sample = df_interpol.explode([\"time\", \"flux\",\"err\"], ignore_index=True)\nmy_sample = my_sample.astype({col: \"float\" for col in [\"time\", \"flux\", \"err\"]})\n\n#reformat the data to have columns be the different flux bands\nmy_sample = reformat_df(my_sample)\n\n#normalize\nmy_sample = local_normalization_max(my_sample, norm_column = \"flux_W1\")\n\n#make datetime column\nmy_sample['datetime'] = mjd_to_datetime(my_sample)\n\n#set index expected by sktime\nmy_sample = my_sample.set_index([\"objectid\", \"label\", \"datetime\"])\n\n#drop the uncertainty and time columns\nmy_sample.drop(columns = ['err_panstarrs_g',\t'err_panstarrs_i',\t'err_panstarrs_r',\t'err_panstarrs_y',\n                          'err_panstarrs_z',\t'err_W1',\t'err_W2',\t'err_zg',\t'err_zr','time'], inplace = True)\n\n #make X\nX_mysample  = my_sample.droplevel('label')","key":"QxcXnYGToj"},{"type":"outputs","id":"dx9AWjVNMDA0P4QfGUiFL","children":[],"key":"XBKfCL3Ohh"}],"key":"be7E6sc1Td"},{"type":"block","children":[],"key":"qG1NtPP13F"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#what does this look like to make sure we are on track\nX_mysample","key":"KfXXEjKCJo"},{"type":"outputs","id":"nltiS761elEfRSnWhDNFI","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"execute_result","execution_count":30,"metadata":{},"data":{"text/plain":{"content":"                                      flux_W1   flux_W2  flux_panstarrs_g  \\\nobjectid datetime                                                           \n1        2009-06-03 06:37:08.765742  1.000000  0.927367          0.140308   \n         2009-08-02 06:37:08.765742  1.000000  0.927367          0.140308   \n         2009-10-01 06:37:08.765742  1.000000  0.927367          0.140308   \n         2009-11-30 06:37:08.765742  1.000000  0.927367          0.140308   \n         2010-01-29 06:37:08.765742  1.000000  0.927367          0.140308   \n...                                       ...       ...               ...   \n458      2022-07-25 06:37:08.765742  0.787245  0.568910          0.118627   \n         2022-09-23 06:37:08.765742  0.787245  0.568910          0.118627   \n         2022-11-22 06:37:08.765742  0.787245  0.568910          0.118627   \n         2023-01-21 06:37:08.765742  0.787245  0.568910          0.118627   \n         2023-03-22 06:37:08.765742  0.787245  0.568910          0.118627   \n\n                                     flux_panstarrs_i  flux_panstarrs_r  \\\nobjectid datetime                                                         \n1        2009-06-03 06:37:08.765742          0.331437          0.267991   \n         2009-08-02 06:37:08.765742          0.331437          0.267991   \n         2009-10-01 06:37:08.765742          0.331437          0.267991   \n         2009-11-30 06:37:08.765742          0.331437          0.267991   \n         2010-01-29 06:37:08.765742          0.331437          0.267991   \n...                                               ...               ...   \n458      2022-07-25 06:37:08.765742          0.414211          0.219828   \n         2022-09-23 06:37:08.765742          0.414211          0.219828   \n         2022-11-22 06:37:08.765742          0.414211          0.219828   \n         2023-01-21 06:37:08.765742          0.414211          0.219828   \n         2023-03-22 06:37:08.765742          0.414211          0.219828   \n\n                                     flux_panstarrs_y  flux_panstarrs_z  \\\nobjectid datetime                                                         \n1        2009-06-03 06:37:08.765742          0.461279          0.464892   \n         2009-08-02 06:37:08.765742          0.461279          0.464892   \n         2009-10-01 06:37:08.765742          0.461279          0.464892   \n         2009-11-30 06:37:08.765742          0.461279          0.464892   \n         2010-01-29 06:37:08.765742          0.461279          0.464892   \n...                                               ...               ...   \n458      2022-07-25 06:37:08.765742          0.393996          0.406282   \n         2022-09-23 06:37:08.765742          0.393996          0.406282   \n         2022-11-22 06:37:08.765742          0.393996          0.406282   \n         2023-01-21 06:37:08.765742          0.393996          0.406282   \n         2023-03-22 06:37:08.765742          0.393996          0.406282   \n\n                                      flux_zg   flux_zr  \nobjectid datetime                                        \n1        2009-06-03 06:37:08.765742  0.116756  0.286475  \n         2009-08-02 06:37:08.765742  0.116756  0.286475  \n         2009-10-01 06:37:08.765742  0.116756  0.286475  \n         2009-11-30 06:37:08.765742  0.116756  0.286475  \n         2010-01-29 06:37:08.765742  0.116756  0.286475  \n...                                       ...       ...  \n458      2022-07-25 06:37:08.765742  0.125963  0.283218  \n         2022-09-23 06:37:08.765742  0.125963  0.311635  \n         2022-11-22 06:37:08.765742  0.135551  0.311296  \n         2023-01-21 06:37:08.765742  0.139684  0.305088  \n         2023-03-22 06:37:08.765742  0.127343  0.265804  \n\n[30345 rows x 9 columns]","content_type":"text/plain"},"text/html":{"content":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>flux_W1</th>\n      <th>flux_W2</th>\n      <th>flux_panstarrs_g</th>\n      <th>flux_panstarrs_i</th>\n      <th>flux_panstarrs_r</th>\n      <th>flux_panstarrs_y</th>\n      <th>flux_panstarrs_z</th>\n      <th>flux_zg</th>\n      <th>flux_zr</th>\n    </tr>\n    <tr>\n      <th>objectid</th>\n      <th>datetime</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">1</th>\n      <th>2009-06-03 06:37:08.765742</th>\n      <td>1.000000</td>\n      <td>0.927367</td>\n      <td>0.140308</td>\n      <td>0.331437</td>\n      <td>0.267991</td>\n      <td>0.461279</td>\n      <td>0.464892</td>\n      <td>0.116756</td>\n      <td>0.286475</td>\n    </tr>\n    <tr>\n      <th>2009-08-02 06:37:08.765742</th>\n      <td>1.000000</td>\n      <td>0.927367</td>\n      <td>0.140308</td>\n      <td>0.331437</td>\n      <td>0.267991</td>\n      <td>0.461279</td>\n      <td>0.464892</td>\n      <td>0.116756</td>\n      <td>0.286475</td>\n    </tr>\n    <tr>\n      <th>2009-10-01 06:37:08.765742</th>\n      <td>1.000000</td>\n      <td>0.927367</td>\n      <td>0.140308</td>\n      <td>0.331437</td>\n      <td>0.267991</td>\n      <td>0.461279</td>\n      <td>0.464892</td>\n      <td>0.116756</td>\n      <td>0.286475</td>\n    </tr>\n    <tr>\n      <th>2009-11-30 06:37:08.765742</th>\n      <td>1.000000</td>\n      <td>0.927367</td>\n      <td>0.140308</td>\n      <td>0.331437</td>\n      <td>0.267991</td>\n      <td>0.461279</td>\n      <td>0.464892</td>\n      <td>0.116756</td>\n      <td>0.286475</td>\n    </tr>\n    <tr>\n      <th>2010-01-29 06:37:08.765742</th>\n      <td>1.000000</td>\n      <td>0.927367</td>\n      <td>0.140308</td>\n      <td>0.331437</td>\n      <td>0.267991</td>\n      <td>0.461279</td>\n      <td>0.464892</td>\n      <td>0.116756</td>\n      <td>0.286475</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">458</th>\n      <th>2022-07-25 06:37:08.765742</th>\n      <td>0.787245</td>\n      <td>0.568910</td>\n      <td>0.118627</td>\n      <td>0.414211</td>\n      <td>0.219828</td>\n      <td>0.393996</td>\n      <td>0.406282</td>\n      <td>0.125963</td>\n      <td>0.283218</td>\n    </tr>\n    <tr>\n      <th>2022-09-23 06:37:08.765742</th>\n      <td>0.787245</td>\n      <td>0.568910</td>\n      <td>0.118627</td>\n      <td>0.414211</td>\n      <td>0.219828</td>\n      <td>0.393996</td>\n      <td>0.406282</td>\n      <td>0.125963</td>\n      <td>0.311635</td>\n    </tr>\n    <tr>\n      <th>2022-11-22 06:37:08.765742</th>\n      <td>0.787245</td>\n      <td>0.568910</td>\n      <td>0.118627</td>\n      <td>0.414211</td>\n      <td>0.219828</td>\n      <td>0.393996</td>\n      <td>0.406282</td>\n      <td>0.135551</td>\n      <td>0.311296</td>\n    </tr>\n    <tr>\n      <th>2023-01-21 06:37:08.765742</th>\n      <td>0.787245</td>\n      <td>0.568910</td>\n      <td>0.118627</td>\n      <td>0.414211</td>\n      <td>0.219828</td>\n      <td>0.393996</td>\n      <td>0.406282</td>\n      <td>0.139684</td>\n      <td>0.305088</td>\n    </tr>\n    <tr>\n      <th>2023-03-22 06:37:08.765742</th>\n      <td>0.787245</td>\n      <td>0.568910</td>\n      <td>0.118627</td>\n      <td>0.414211</td>\n      <td>0.219828</td>\n      <td>0.393996</td>\n      <td>0.406282</td>\n      <td>0.127343</td>\n      <td>0.265804</td>\n    </tr>\n  </tbody>\n</table>\n<p>30345 rows × 9 columns</p>\n</div>","content_type":"text/html"}}},"key":"eGBESGfBv7"}],"key":"BLGXvdj9Yr"}],"key":"NC1U1zw3wO"},{"type":"block","children":[],"key":"ZbjmPyWdTd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#use the trained sktime algorithm to make predictions on the test dataset\ny_mysample = clf.predict(X_mysample)","key":"ZxW4Obo6zX"},{"type":"outputs","id":"XJaz0qIY3Wad_ZcIcku2u","children":[],"key":"eyRHxjybv1"}],"key":"fqQbi3TmLe"},{"type":"block","children":[],"key":"MPUhIZIqMw"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#access the sample_table made in the light_curve_collector notebook\n#has information about the sample including ra & dec\nsavename_sample = './data/small_CLAGN_SDSS_sample.ecsv'\ngdd.download_file_from_google_drive(file_id='1pSEKVP4LbrdWQK9ws3CaI90m3Z_2fazL',\n                                    dest_path=savename_sample,\n                                    unzip=True)\nsample_table = Table.read(savename_sample, format='ascii.ecsv')","key":"a1i1YtVBry"},{"type":"outputs","id":"b_Rs4UzAnldEgBLOGZNLI","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Downloading 1pSEKVP4LbrdWQK9ws3CaI90m3Z_2fazL into ./data/small_CLAGN_SDSS_sample.ecsv... "},"key":"MB7MasgBXn"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stdout","text":"Done.\nUnzipping..."},"key":"T79GTLVEf3"},{"type":"output","children":[],"jupyter_data":{"output_type":"stream","name":"stderr","text":"/home/runner/work/fornax-demo-notebooks/fornax-demo-notebooks/.tox/py312-buildhtml/lib/python3.12/site-packages/googledrivedownloader/download.py:88: UserWarning: Ignoring `unzip` since \"1pSEKVP4LbrdWQK9ws3CaI90m3Z_2fazL\" does not look like a valid zip file\n  warnings.warn('Ignoring `unzip` since \"{}\" does not look like a valid zip file'.format(file_id))\n"},"key":"z6uHz9CNAu"}],"key":"Op625XdEGD"}],"key":"IHLg1vhIVT"},{"type":"block","children":[],"key":"K9yEsyOtS4"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#associate these predicted CLAGN with RA & Dec\n\n#need to first associate objectid with each of y_mysample\n#make a new df with a column = objectid which\n#includes all the unique objectids.\ntest = X_mysample.reset_index()\nmysample_CLAGN = pd.DataFrame(test.objectid.unique(), columns = ['objectid'])\nmysample_CLAGN[\"predicted_label\"] = pd.Series(y_mysample)\n\n#if I am only interested in the CLAGN, could drop anything with label = SDSS\nquerystring = 'predicted_label == \"SDSS\"'\nmysample_CLAGN = mysample_CLAGN.drop(mysample_CLAGN.query(querystring ).index)\n\n#then will need to merge candidate_CLAGN with sample_table along objectid\nsample_table_df = sample_table.to_pandas()\ncandidate_CLAGN = pd.merge(mysample_CLAGN, sample_table_df, on = \"objectid\", how = \"inner\")","key":"hMIOVxBd2u"},{"type":"outputs","id":"8qHMSuxJABWCjonUPiFDT","children":[],"key":"YqRpCZo7VI"}],"key":"bpvy3Jv4MR"},{"type":"block","children":[],"key":"en8ATWiCJv"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"#show the CLAGN candidates ra & dec\ncandidate_CLAGN","key":"Nli1xfNkr8"},{"type":"outputs","id":"ppKvVGjXKN1tlPCm2wfcj","children":[{"type":"output","children":[],"jupyter_data":{"output_type":"execute_result","execution_count":34,"metadata":{},"data":{"text/plain":{"content":"     objectid predicted_label    coord.ra  coord.dec       label\n0           1           CLAGN   29.990000   0.553010  LaMassa 15\n1           2           CLAGN    5.796083   0.588203    Green 22\n2           3           CLAGN   36.483625   0.507417  MacLeod 16\n3           5           CLAGN  150.584042  45.157583  MacLeod 16\n4           6           CLAGN  155.468083  46.754333  MacLeod 16\n..        ...             ...         ...        ...         ...\n96        282           CLAGN  161.163170  38.759552        SDSS\n97        314           CLAGN  259.412720  32.704313        SDSS\n98        380           CLAGN  188.156210  66.414533        SDSS\n99        392           CLAGN  246.670540  14.378788        SDSS\n100       415           CLAGN  200.730970   8.161559        SDSS\n\n[101 rows x 5 columns]","content_type":"text/plain"},"text/html":{"content":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>objectid</th>\n      <th>predicted_label</th>\n      <th>coord.ra</th>\n      <th>coord.dec</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>CLAGN</td>\n      <td>29.990000</td>\n      <td>0.553010</td>\n      <td>LaMassa 15</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>CLAGN</td>\n      <td>5.796083</td>\n      <td>0.588203</td>\n      <td>Green 22</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>CLAGN</td>\n      <td>36.483625</td>\n      <td>0.507417</td>\n      <td>MacLeod 16</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>CLAGN</td>\n      <td>150.584042</td>\n      <td>45.157583</td>\n      <td>MacLeod 16</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>CLAGN</td>\n      <td>155.468083</td>\n      <td>46.754333</td>\n      <td>MacLeod 16</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>282</td>\n      <td>CLAGN</td>\n      <td>161.163170</td>\n      <td>38.759552</td>\n      <td>SDSS</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>314</td>\n      <td>CLAGN</td>\n      <td>259.412720</td>\n      <td>32.704313</td>\n      <td>SDSS</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>380</td>\n      <td>CLAGN</td>\n      <td>188.156210</td>\n      <td>66.414533</td>\n      <td>SDSS</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>392</td>\n      <td>CLAGN</td>\n      <td>246.670540</td>\n      <td>14.378788</td>\n      <td>SDSS</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>415</td>\n      <td>CLAGN</td>\n      <td>200.730970</td>\n      <td>8.161559</td>\n      <td>SDSS</td>\n    </tr>\n  </tbody>\n</table>\n<p>101 rows × 5 columns</p>\n</div>","content_type":"text/html"}}},"key":"DMGZW5oHcx"}],"key":"UJsqYASuza"}],"key":"BaEMZvpMVj"},{"type":"block","children":[{"type":"heading","depth":2,"position":{"start":{"line":685,"column":1},"end":{"line":685,"column":1}},"children":[{"type":"text","value":"Conclusions","position":{"start":{"line":685,"column":1},"end":{"line":685,"column":1}},"key":"iXjhQuxWLf"}],"identifier":"conclusions","label":"Conclusions","html_id":"conclusions","implicit":true,"key":"vcRxmmLogj"},{"type":"paragraph","position":{"start":{"line":687,"column":1},"end":{"line":687,"column":1}},"children":[{"type":"text","value":"Depending on your comfort level with the accuracy of the classifier you have trained, you could now write an observing proposal to confirm those targets prediced to be CLAGN based on their multiwavelength light curves.","position":{"start":{"line":687,"column":1},"end":{"line":687,"column":1}},"key":"TSYY1Dp1gz"}],"key":"jg3zIB6Xnd"}],"key":"ou67hg7YHn"},{"type":"block","position":{"start":{"line":689,"column":1},"end":{"line":689,"column":1}},"children":[{"type":"heading","depth":2,"position":{"start":{"line":691,"column":1},"end":{"line":691,"column":1}},"children":[{"type":"text","value":"About this notebook","position":{"start":{"line":691,"column":1},"end":{"line":691,"column":1}},"key":"ftSd49EbnE"}],"identifier":"about-this-notebook","label":"About this notebook","html_id":"about-this-notebook","implicit":true,"key":"KWS243nA9x"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":693,"column":1},"end":{"line":695,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":693,"column":1},"end":{"line":693,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":693,"column":1},"end":{"line":693,"column":1}},"children":[{"type":"text","value":"Authors:","position":{"start":{"line":693,"column":1},"end":{"line":693,"column":1}},"key":"WDukSPnsiU"}],"key":"CPMXf8fdvJ"},{"type":"text","value":" Jessica Krick, Shoubaneh Hemmati, Troy Raen, Brigitta Sipőcz, Andreas Faisst, Vandana Desai, David Shupe, and the Fornax team","position":{"start":{"line":693,"column":1},"end":{"line":693,"column":1}},"key":"in528q0nRY"}],"key":"Fo06UGXrR8"}],"key":"seDXjSqfbh"},{"type":"listItem","spread":true,"position":{"start":{"line":694,"column":1},"end":{"line":695,"column":1}},"children":[{"type":"paragraph","children":[{"type":"strong","position":{"start":{"line":694,"column":1},"end":{"line":694,"column":1}},"children":[{"type":"text","value":"Contact:","position":{"start":{"line":694,"column":1},"end":{"line":694,"column":1}},"key":"w0Oa7tVdQm"}],"key":"jrCK3zTYvV"},{"type":"text","value":" For help with this notebook, please open a topic in the ","position":{"start":{"line":694,"column":1},"end":{"line":694,"column":1}},"key":"ZauuyIqwdz"},{"type":"link","url":"https://discourse.fornax.sciencecloud.nasa.gov/","position":{"start":{"line":694,"column":1},"end":{"line":694,"column":1}},"children":[{"type":"text","value":"Fornax Community Forum","position":{"start":{"line":694,"column":1},"end":{"line":694,"column":1}},"key":"L8ImXrCOhO"}],"urlSource":"https://discourse.fornax.sciencecloud.nasa.gov/","key":"T7HcGoD2fM"},{"type":"text","value":" “Support” category.","position":{"start":{"line":694,"column":1},"end":{"line":694,"column":1}},"key":"TrqKRYMJPt"}],"key":"a3D1HstcD4"}],"key":"zYOq3pQVfh"}],"key":"usmln7UZVe"},{"type":"heading","depth":3,"position":{"start":{"line":696,"column":1},"end":{"line":696,"column":1}},"children":[{"type":"text","value":"Acknowledgements","position":{"start":{"line":696,"column":1},"end":{"line":696,"column":1}},"key":"wqaVHOFQAw"}],"identifier":"acknowledgements","label":"Acknowledgements","html_id":"acknowledgements","implicit":true,"key":"drMa7m95yL"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":698,"column":1},"end":{"line":699,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":698,"column":1},"end":{"line":699,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"Stephanie La Massa","position":{"start":{"line":698,"column":1},"end":{"line":698,"column":1}},"key":"aMSLf61DJT"}],"key":"ScvingH0rw"}],"key":"EaYjLxdwUP"}],"key":"iLU8AxMRIG"},{"type":"heading","depth":3,"position":{"start":{"line":700,"column":1},"end":{"line":700,"column":1}},"children":[{"type":"text","value":"References","position":{"start":{"line":700,"column":1},"end":{"line":700,"column":1}},"key":"UBqhQ2pmdo"}],"identifier":"references","label":"References","html_id":"references","implicit":true,"key":"Ynn05I4Khw"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":702,"column":1},"end":{"line":706,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":702,"column":1},"end":{"line":703,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"“sktime: A Unified Interface for Machine Learning with Time Series”\nMarkus Löning, Tony Bagnall, Sajaysurya Ganesh, George Oastler, Jason Lines, ViktorKaz, …, Aadesh Deshmukh (2020). sktime/sktime. Zenodo. ","position":{"start":{"line":702,"column":1},"end":{"line":702,"column":1}},"key":"xRCbsfuGXB"},{"type":"cite","url":"http://doi.org/10.5281/zenodo.3749000","position":{"start":{"line":702,"column":1},"end":{"line":702,"column":1}},"children":[{"type":"text","value":"Franz Király ","key":"KpsVxt6GG5"},{"type":"emphasis","children":[{"type":"text","value":"et al.","key":"SBh0IPdEmF"}],"key":"BzPaRfXeTR"},{"type":"text","value":" (2025)","key":"FYCpyII3R1"}],"kind":"narrative","label":"https://doi.org/10.5281/zenodo.3749000","identifier":"http://doi.org/10.5281/zenodo.3749000","enumerator":"1","key":"eIfkT81Sn4"}],"key":"SJxH0Fu34W"}],"key":"HKxLN2cZ4c"},{"type":"listItem","spread":true,"position":{"start":{"line":704,"column":1},"end":{"line":704,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"“Scikit-learn: Machine Learning in Python”, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.","position":{"start":{"line":704,"column":1},"end":{"line":704,"column":1}},"key":"jZ48CdNaVE"}],"key":"DcDOrYHJo1"}],"key":"D8L9yhviKD"},{"type":"listItem","spread":true,"position":{"start":{"line":705,"column":1},"end":{"line":705,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"“pandas-dev/pandas: Pandas” The pandas development team, 2020. Zenodo. ","position":{"start":{"line":705,"column":1},"end":{"line":705,"column":1}},"key":"pN5BDxMU5c"},{"type":"cite","url":"https://doi.org/10.5281/zenodo.3509134","position":{"start":{"line":705,"column":1},"end":{"line":705,"column":1}},"children":[{"type":"text","value":"team (2026)","key":"W8cvznXWZJ"}],"kind":"narrative","label":"https://doi.org/10.5281/zenodo.3509134","identifier":"https://doi.org/10.5281/zenodo.3509134","enumerator":"2","key":"S1q9HjIwBj"}],"key":"YuRKcTlkZw"}],"key":"bQ7ZpKBaJg"},{"type":"listItem","spread":true,"position":{"start":{"line":706,"column":1},"end":{"line":706,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"This work made use of ","position":{"start":{"line":706,"column":1},"end":{"line":706,"column":1}},"key":"LzWHBi5nal"},{"type":"link","url":"http://www.astropy.org","position":{"start":{"line":706,"column":1},"end":{"line":706,"column":1}},"children":[{"type":"text","value":"Astropy","position":{"start":{"line":706,"column":1},"end":{"line":706,"column":1}},"key":"nGz8ppsTeD"}],"urlSource":"http://www.astropy.org","key":"Kv0ozig64l"},{"type":"text","value":" a community-developed core Python package and an ecosystem of tools and resources for astronomy (astropy:2013, astropy:2018, astropy:2022).","position":{"start":{"line":706,"column":1},"end":{"line":706,"column":1}},"key":"FTgQ4wmGus"}],"key":"w8NxtMl1Yt"}],"key":"doohjLv4ZO"}],"key":"K2gFiHpuMN"}],"key":"sAEyoWWKiz"}],"key":"PrePYYV6Px"},"references":{"cite":{"order":["https://doi.org/10.5281/zenodo.3749000","https://doi.org/10.5281/zenodo.3509134"],"data":{"https://doi.org/10.5281/zenodo.3749000":{"label":"https://doi.org/10.5281/zenodo.3749000","enumerator":"1","doi":"10.5281/ZENODO.3749000","html":"Franz Király, Markus Löning, Tony Bagnall, Matthew Middlehurst, Anirban Ray, Sajaysurya Ganesh, Martin Walter, George Oastler, Jason Lines, ViktorKaz, Benedikt Heidrich, Lukasz Mentel, Jigyasu, Sagar Mishra, chrisholder, Daniel Bartling, Armaghan Shakir, Leonidas Tsaprounis, RNKuhns, … Taiwo Owoseni. (2025). <i>sktime/sktime: v0.40.1</i>. Zenodo. <a target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.5281/ZENODO.3749000\">10.5281/ZENODO.3749000</a>","url":"https://doi.org/10.5281/ZENODO.3749000"},"https://doi.org/10.5281/zenodo.3509134":{"label":"https://doi.org/10.5281/zenodo.3509134","enumerator":"2","doi":"10.5281/ZENODO.3509134","html":"The pandas development team. (2026). <i>pandas-dev/pandas: Pandas</i>. Zenodo. <a target=\"_blank\" rel=\"noreferrer\" href=\"https://doi.org/10.5281/ZENODO.3509134\">10.5281/ZENODO.3509134</a>","url":"https://doi.org/10.5281/ZENODO.3509134"}}}},"footer":{"navigation":{"prev":{"title":"Make Multi-Wavelength Light Curves for Large Samples","url":"/scale-up","group":"The Fornax Initiative"},"next":{"title":"AGN Zoo: Comparison of AGN selected with different metrics","url":"/ml-agnzoo","group":"The Fornax Initiative"}}},"domain":"http://localhost:3000"}