{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Multiband Forced Photometry on Large Datasets\n",
    "***\n",
    "\n",
    "## Learning Goals:\n",
    "By the end of this tutorial, you will be able to:\n",
    "- get catalogs and images from NASA archives in the cloud where possible\n",
    "- measure fluxes at any location by running forced photometry using \"The Tractor\" \n",
    "- employ parallel processing to make this as fast as possible\n",
    "- cross match large catalogs\n",
    "- plot results\n",
    "\n",
    "## Introduction:\n",
    "This code performs photometry in an automated fashion at all locations in an input catalog on 4 bands of IRAC data from IRSA and 2 bands of Galex data from MAST.  The resulting catalog is then cross-matched with a Chandra catalog from HEASARC to generate a multiband catalog to facilitate galaxy evolution studies.\n",
    "\n",
    "The code will run on 2 different science platforms and makes full use of multiple processors to optimize run time on large datasets.\n",
    "\n",
    "## Input:\n",
    "- RA and DEC within COSMOS catalog\n",
    "- desired catalog radius in arcminutes\n",
    "- mosaics of that region for IRAC and Galex\n",
    "\n",
    "## Output:\n",
    "- merged, multiband, science ready pandas dataframe\n",
    "- IRAC color color plot for identifying interesting populations\n",
    "\n",
    "## Non-standard Imports\n",
    "- `tractor` code which does the forced photometry from Lang et al., 2016\n",
    "- `astroquery` to interface with archives APIs\n",
    "- `astropy` to work with coordinates/units and data structures\n",
    "- `skimage` to work with the images\n",
    "\n",
    "\n",
    "## Authors:\n",
    "Jessica Krick, David Shupe, Marziye JafariYazani, Brigitta Sipőcz, Vandana Desai, Steve Groom, Troy Raen\n",
    "\n",
    "\n",
    "## Acknowledgements:\n",
    "Kristina Nyland for the workflow of the tractor wrapper.\\\n",
    "MAST, HEASARC, & IRSA Fornax teams\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /srv/conda/envs/tractor/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (1.22.0)\n",
      "Requirement already satisfied: matplotlib in /srv/conda/envs/tractor/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.5.3)\n",
      "Requirement already satisfied: scikit-image in /home/jovyan/.local/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (0.19.3)\n",
      "Requirement already satisfied: pandas in /srv/conda/envs/tractor/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.4.3)\n",
      "Requirement already satisfied: seaborn in /srv/conda/envs/tractor/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.11.2)\n",
      "Requirement already satisfied: statsmodels in /srv/conda/envs/tractor/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.13.2)\n",
      "Requirement already satisfied: mpld3 in /home/jovyan/.local/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.5.8)\n",
      "Requirement already satisfied: firefly_client in /home/jovyan/.local/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.8.0)\n",
      "Requirement already satisfied: astropy in /srv/conda/envs/tractor/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (5.1)\n",
      "Requirement already satisfied: astroquery in /srv/conda/envs/tractor/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (0.4.6)\n",
      "Requirement already satisfied: nway in /home/jovyan/.local/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (4.5.2)\n",
      "Requirement already satisfied: boto3 in /home/jovyan/.local/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (1.24.49)\n",
      "Requirement already satisfied: tqdm in /home/jovyan/.local/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (4.64.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (4.37.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from matplotlib->-r requirements.txt (line 5)) (21.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 6)) (1.9.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/jovyan/.local/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 6)) (2.8.7)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/jovyan/.local/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 6)) (2022.8.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/jovyan/.local/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 6)) (1.4.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/jovyan/.local/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 6)) (2.22.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 7)) (2022.2.1)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from statsmodels->-r requirements.txt (line 9)) (0.5.2)\n",
      "Requirement already satisfied: jinja2 in /home/jovyan/.local/lib/python3.10/site-packages (from mpld3->-r requirements.txt (line 10)) (3.1.2)\n",
      "Requirement already satisfied: websocket-client in /home/jovyan/.local/lib/python3.10/site-packages (from firefly_client->-r requirements.txt (line 11)) (1.4.1)\n",
      "Requirement already satisfied: requests in /srv/conda/envs/tractor/lib/python3.10/site-packages (from firefly_client->-r requirements.txt (line 11)) (2.28.1)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from astropy->-r requirements.txt (line 12)) (6.0)\n",
      "Requirement already satisfied: pyerfa>=2.0 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from astropy->-r requirements.txt (line 12)) (2.0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.3.2 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from astroquery->-r requirements.txt (line 13)) (4.11.1)\n",
      "Requirement already satisfied: html5lib>=0.999 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from astroquery->-r requirements.txt (line 13)) (1.1)\n",
      "Requirement already satisfied: keyring>=4.0 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from astroquery->-r requirements.txt (line 13)) (23.8.2)\n",
      "Requirement already satisfied: pyvo>=1.1 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from astroquery->-r requirements.txt (line 13)) (1.3)\n",
      "Requirement already satisfied: joblib in /home/jovyan/.local/lib/python3.10/site-packages (from nway->-r requirements.txt (line 14)) (1.2.0)\n",
      "Requirement already satisfied: healpy in /home/jovyan/.local/lib/python3.10/site-packages (from nway->-r requirements.txt (line 14)) (1.16.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/jovyan/.local/lib/python3.10/site-packages (from boto3->-r requirements.txt (line 15)) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.49 in /home/jovyan/.local/lib/python3.10/site-packages (from boto3->-r requirements.txt (line 15)) (1.27.49)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/jovyan/.local/lib/python3.10/site-packages (from boto3->-r requirements.txt (line 15)) (1.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from beautifulsoup4>=4.3.2->astroquery->-r requirements.txt (line 13)) (2.3.2.post1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from botocore<1.28.0,>=1.27.49->boto3->-r requirements.txt (line 15)) (1.26.11)\n",
      "Requirement already satisfied: webencodings in /srv/conda/envs/tractor/lib/python3.10/site-packages (from html5lib>=0.999->astroquery->-r requirements.txt (line 13)) (0.5.1)\n",
      "Requirement already satisfied: six>=1.9 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from html5lib>=0.999->astroquery->-r requirements.txt (line 13)) (1.16.0)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from keyring>=4.0->astroquery->-r requirements.txt (line 13)) (3.3.3)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from keyring>=4.0->astroquery->-r requirements.txt (line 13)) (0.8.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from requests->firefly_client->-r requirements.txt (line 11)) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from requests->firefly_client->-r requirements.txt (line 11)) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from requests->firefly_client->-r requirements.txt (line 11)) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jovyan/.local/lib/python3.10/site-packages (from jinja2->mpld3->-r requirements.txt (line 10)) (2.1.1)\n",
      "Requirement already satisfied: cryptography>=2.0 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from SecretStorage>=3.2->keyring>=4.0->astroquery->-r requirements.txt (line 13)) (37.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /srv/conda/envs/tractor/lib/python3.10/site-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=4.0->astroquery->-r requirements.txt (line 13)) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /srv/conda/envs/tractor/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=4.0->astroquery->-r requirements.txt (line 13)) (2.21)\n"
     ]
    }
   ],
   "source": [
    "#ensure all dependencies are installed\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard lib imports\n",
    "\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "import concurrent.futures\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from typing import NamedTuple\n",
    "\n",
    "# Third party imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import rotate\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels\n",
    "import mpld3\n",
    "from tqdm import tqdm\n",
    "\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "from astroquery.ipac.irsa import Irsa\n",
    "from astroquery.heasarc import Heasarc\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# Local code imports\n",
    "sys.path.append('../code/')\n",
    "\n",
    "from display_images import display_images\n",
    "import cutout\n",
    "from exceptions import TractorError\n",
    "import photometry\n",
    "from plot_SED import plot_SED\n",
    "from nway_write_header import nway_write_header\n",
    "from photometry import Band\n",
    "from photometry import lookup_img_pair\n",
    "#from prepare_prf import prepare_prf\n",
    "\n",
    "# temporarily let the notebook start without tractor as dependency\n",
    "try:\n",
    "    from find_nconfsources import find_nconfsources\n",
    "except ImportError:\n",
    "    print(\"tractor is missing\")\n",
    "    pass\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieve Initial Catalog from IRSA\n",
    "- Automatically set up a catalog with ra, dec, photometric redshifts, fiducial band fluxes, & probability that it is a star  \n",
    "- Catalog we are using is COSMOS2015 (Laigle et al. 2016)  \n",
    "- Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of objects:  100\n"
     ]
    }
   ],
   "source": [
    "#pull a COSMOS catalog from IRSA using astroquery\n",
    "\n",
    "#make sure the archive isn't limiting our search\n",
    "#default values of row_limit are often much lower than what we might want \n",
    "Irsa.ROW_LIMIT = 3E6  \n",
    "Irsa.TIMEOUT = 600\n",
    "\n",
    "\n",
    "#what is the central RA and DEC of the desired catalog\n",
    "coords = SkyCoord('150.01d 2.2d', frame='icrs')  #COSMOS center acording to Simbad\n",
    "\n",
    "#how large is the search radius, in arcmin\n",
    "radius = 0.5 * u.arcmin #full COSMOS is 40arcmin\n",
    "\n",
    "#use Astroquery to get the catalog\n",
    "#specify only select columns to limit the size of the catalog\n",
    "cols = [\n",
    "    'ra', 'dec', 'id', 'Ks_FLUX_APER2', 'Ks_FLUXERR_APER2', 'PHOTOZ', 'SPLASH_1_MAG',\n",
    "    'SPLASH_1_MAGERR', 'SPLASH_1_FLUX', 'SPLASH_1_FLUX_ERR', 'SPLASH_2_FLUX',\n",
    "    'SPLASH_2_FLUX_ERR', 'SPLASH_3_FLUX', 'SPLASH_3_FLUX_ERR', 'SPLASH_4_FLUX',\n",
    "    'SPLASH_4_FLUX_ERR', 'FLUX_GALEX_NUV', 'FLUX_GALEX_FUV', 'FLUX_CHANDRA_05_2',\n",
    "    'FLUX_CHANDRA_2_10', 'FLUX_CHANDRA_05_10', 'ID_CHANDRA09 ', 'type', 'r_MAG_AUTO',\n",
    "    'r_MAGERR_AUTO', 'FLUX_24', 'FLUXERR_24', 'MAG_GALEX_NUV', 'MAGERR_GALEX_NUV',\n",
    "    'MAG_GALEX_FUV', 'MAGERR_GALEX_FUV'\n",
    "]\n",
    "cosmos_table = Irsa.query_region(coords, catalog=\"cosmos2015\", radius=radius, selcols=','.join(cols))\n",
    "\n",
    "\n",
    "print(\"Number of objects: \", len(cosmos_table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Filter Catalog\n",
    "- if desired could filter the initial catalog to only include desired sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an example of how to filter the catalog to \n",
    "#select those rows with either chandra fluxes or Galex NUV fluxes\n",
    "\n",
    "#example_table = cosmos_table[(cosmos_table['flux_chandra_05_10']> 0) | (cosmos_table['flux_galex_fuv'] > 0)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve Image Datasets from the Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the fornax cloud access API to obtain the IRAC data from the IRSA S3 bucket. \n",
    "\n",
    "Details here may change as the prototype code is being added to the appropriate libraries, as well as the data holding to the appropriate NGAP storage as opposed to IRSA resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary solution, remove when the fornax API is added to the image\n",
    "# This relies on the assumption that https://github.com/fornax-navo/fornax-cloud-access-API is being cloned to this environment. \n",
    "# If it's not, then run a ``git clone https://github.com/fornax-navo/fornax-cloud-access-API --depth=1`` from a terminal at the highest directory root.\n",
    "# You may need to update the fork if you forked it in the past\n",
    "\n",
    "import os\n",
    "if not os.path.exists('../../fornax-cloud-access-API'):\n",
    "    ! git clone https://github.com/fornax-navo/fornax-cloud-access-API --depth=1 ../../fornax-cloud-access-API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../fornax-cloud-access-API')\n",
    "\n",
    "import pyvo\n",
    "import fornax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the COSMOS address from the registry to follow PyVO user case approach. We could hardwire it.\n",
    "image_services = pyvo.regsearch(servicetype='image')\n",
    "irsa_cosmos = [s for s in image_services if 'irsa' in s.ivoid and 'cosmos' in s.ivoid][0]\n",
    "\n",
    "# The search returns 11191 entries, but unfortunately we cannot really filter efficiently in the query\n",
    "# itself (https://irsa.ipac.caltech.edu/applications/Atlas/AtlasProgramInterface.html#inputparam)\n",
    "# to get only the Spitzer IRAC results from COSMOS as a mission. We will do the filtering in a next step before download.\n",
    "cosmos_results = irsa_cosmos.search(coords).to_table()\n",
    "\n",
    "spitzer = cosmos_results[cosmos_results['dataset'] == 'IRAC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily add the cloud_access metadata to the Atlas response. \n",
    "# This dataset has limited acces, thus 'region' should be used instead of 'open'.\n",
    "# S3 access should be available from the daskhub and those who has their IRSA token set up.\n",
    "\n",
    "fname = spitzer['fname']\n",
    "spitzer['cloud_access'] = [(f'{{\"aws\": {{ \"bucket_name\": \"irsa-mast-tike-spitzer-data\",'\n",
    "                            f'              \"region\": \"us-east-1\",'\n",
    "                            f'              \"access\": \"restricted\",'\n",
    "                            f'              \"key\": \"data/COSMOS/{fn}\" }} }}') for fn in fname]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding function to download multiple files using the fornax API. \n",
    "# Requires https://github.com/fornax-navo/fornax-cloud-access-API/pull/4\n",
    "def fornax_download(data_table, data_directory='../data', access_url_column='access_url',\n",
    "                    fname_filter=None, verbose=False):\n",
    "    working_dir = os.getcwd()\n",
    "    \n",
    "    os.makedirs(data_directory, exist_ok=True)\n",
    "    os.chdir(data_directory)\n",
    "    for row in data_table:\n",
    "        if fname_filter is not None and fname_filter not in row['fname']:\n",
    "            continue\n",
    "        handler = fornax.get_data_product(row, 'aws', access_url_column=access_url_column, verbose=verbose)\n",
    "        temp_file = handler.download()\n",
    "        # on-prem download returns temp file path, s3 download downloads file\n",
    "        if temp_file:\n",
    "            os.rename(temp_file, os.path.basename(row['fname']))\n",
    "        \n",
    "    os.chdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fornax_download(spitzer, access_url_column='sia_url', fname_filter='go2_sci', \n",
    "                data_directory='../data/IRAC', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use astroquery.mast to obtain Galex from the MAST archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the Galex mosaic of COSMOS is broken into 4 seperate images\n",
    "#need to know which Galex image the targets are nearest to.\n",
    "#make a new column in dataframe which figures this out\n",
    "\n",
    "#four centers for 1, 2, 3, 4 are\n",
    "ra_center=[150.369,150.369,149.869,149.869]\n",
    "dec_center=[2.45583,1.95583,2.45583,1.95583]\n",
    "\n",
    "#ra_center = 150.369\n",
    "#dec_center = 2.45583\n",
    "galex = SkyCoord(ra = ra_center*u.degree, dec = dec_center*u.degree)\n",
    "catalog = SkyCoord(ra = cosmos_table['ra'], dec = cosmos_table['dec'])\n",
    "#idx, d2d, d3d = match_coordinates_sky(galex, catalog)  #only finds the nearest one\n",
    "#idx, d2d, d3d = galex.match_to_catalog_sky(catalog)  #only finds the nearest one\n",
    "\n",
    "cosmos_table['COSMOS_01'] = galex[0].separation(catalog)\n",
    "cosmos_table['COSMOS_02'] = galex[1].separation(catalog)\n",
    "cosmos_table['COSMOS_03'] = galex[2].separation(catalog)\n",
    "cosmos_table['COSMOS_04'] = galex[3].separation(catalog)\n",
    "\n",
    "#convert to pandas\n",
    "df = cosmos_table.to_pandas()\n",
    "\n",
    "#which row has the minimum value of distance to the galex images\n",
    "df['galex_image'] = df[['COSMOS_01','COSMOS_02','COSMOS_03','COSMOS_04']].idxmin(axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>id</th>\n",
       "      <th>ks_flux_aper2</th>\n",
       "      <th>ks_fluxerr_aper2</th>\n",
       "      <th>photoz</th>\n",
       "      <th>splash_1_mag</th>\n",
       "      <th>splash_1_magerr</th>\n",
       "      <th>splash_1_flux</th>\n",
       "      <th>splash_1_flux_err</th>\n",
       "      <th>...</th>\n",
       "      <th>mag_galex_nuv</th>\n",
       "      <th>magerr_galex_nuv</th>\n",
       "      <th>mag_galex_fuv</th>\n",
       "      <th>magerr_galex_fuv</th>\n",
       "      <th>dist</th>\n",
       "      <th>angle</th>\n",
       "      <th>COSMOS_01</th>\n",
       "      <th>COSMOS_02</th>\n",
       "      <th>COSMOS_03</th>\n",
       "      <th>COSMOS_04</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>150.010318</td>\n",
       "      <td>2.199147</td>\n",
       "      <td>590981.360000</td>\n",
       "      <td>7.594302</td>\n",
       "      <td>0.215448</td>\n",
       "      <td>1.233854</td>\n",
       "      <td>23.413717</td>\n",
       "      <td>0.075627</td>\n",
       "      <td>7.649175</td>\n",
       "      <td>0.090619</td>\n",
       "      <td>...</td>\n",
       "      <td>25.905962</td>\n",
       "      <td>1.148162</td>\n",
       "      <td>24.977410</td>\n",
       "      <td>0.309080</td>\n",
       "      <td>19.272429</td>\n",
       "      <td>171.621108</td>\n",
       "      <td>0.440843</td>\n",
       "      <td>0.433247</td>\n",
       "      <td>0.292982</td>\n",
       "      <td>0.281360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>2881.596648</td>\n",
       "      <td>38.580495</td>\n",
       "      <td>0.014520</td>\n",
       "      <td>0.815265</td>\n",
       "      <td>1.888851</td>\n",
       "      <td>0.096670</td>\n",
       "      <td>21.369673</td>\n",
       "      <td>0.161176</td>\n",
       "      <td>...</td>\n",
       "      <td>1.719588</td>\n",
       "      <td>1.527069</td>\n",
       "      <td>1.607946</td>\n",
       "      <td>0.281957</td>\n",
       "      <td>6.817253</td>\n",
       "      <td>96.033885</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.003994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>150.002524</td>\n",
       "      <td>2.191851</td>\n",
       "      <td>585578.000000</td>\n",
       "      <td>-0.078000</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.301000</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>-0.016000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.457100</td>\n",
       "      <td>0.026200</td>\n",
       "      <td>22.847600</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>2.219884</td>\n",
       "      <td>1.327525</td>\n",
       "      <td>0.432705</td>\n",
       "      <td>0.425733</td>\n",
       "      <td>0.284810</td>\n",
       "      <td>0.273869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>150.007165</td>\n",
       "      <td>2.195593</td>\n",
       "      <td>588399.750000</td>\n",
       "      <td>0.363500</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>0.751250</td>\n",
       "      <td>21.992375</td>\n",
       "      <td>0.015350</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.860825</td>\n",
       "      <td>0.170325</td>\n",
       "      <td>23.312050</td>\n",
       "      <td>0.048625</td>\n",
       "      <td>14.629402</td>\n",
       "      <td>102.408427</td>\n",
       "      <td>0.437680</td>\n",
       "      <td>0.430057</td>\n",
       "      <td>0.289658</td>\n",
       "      <td>0.278412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>150.010619</td>\n",
       "      <td>2.199306</td>\n",
       "      <td>591215.000000</td>\n",
       "      <td>0.970500</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.985500</td>\n",
       "      <td>23.798450</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>1.036000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>...</td>\n",
       "      <td>26.219200</td>\n",
       "      <td>0.648500</td>\n",
       "      <td>25.765250</td>\n",
       "      <td>0.277450</td>\n",
       "      <td>19.451089</td>\n",
       "      <td>166.727549</td>\n",
       "      <td>0.441183</td>\n",
       "      <td>0.433150</td>\n",
       "      <td>0.293005</td>\n",
       "      <td>0.281117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>150.013524</td>\n",
       "      <td>2.202758</td>\n",
       "      <td>593364.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.219000</td>\n",
       "      <td>1.643750</td>\n",
       "      <td>24.753875</td>\n",
       "      <td>0.099250</td>\n",
       "      <td>5.636000</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>...</td>\n",
       "      <td>27.148450</td>\n",
       "      <td>1.422025</td>\n",
       "      <td>26.211375</td>\n",
       "      <td>0.466375</td>\n",
       "      <td>25.166258</td>\n",
       "      <td>246.121820</td>\n",
       "      <td>0.443729</td>\n",
       "      <td>0.436673</td>\n",
       "      <td>0.296566</td>\n",
       "      <td>0.284188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>150.017355</td>\n",
       "      <td>2.207602</td>\n",
       "      <td>596794.000000</td>\n",
       "      <td>374.985000</td>\n",
       "      <td>0.231000</td>\n",
       "      <td>3.895000</td>\n",
       "      <td>27.274900</td>\n",
       "      <td>0.596800</td>\n",
       "      <td>173.615000</td>\n",
       "      <td>1.455000</td>\n",
       "      <td>...</td>\n",
       "      <td>28.903600</td>\n",
       "      <td>7.206000</td>\n",
       "      <td>26.790400</td>\n",
       "      <td>0.767200</td>\n",
       "      <td>29.821238</td>\n",
       "      <td>359.357019</td>\n",
       "      <td>0.448870</td>\n",
       "      <td>0.442081</td>\n",
       "      <td>0.300047</td>\n",
       "      <td>0.289890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ra         dec             id  ks_flux_aper2  ks_fluxerr_aper2  \\\n",
       "count  100.000000  100.000000     100.000000      96.000000         96.000000   \n",
       "mean   150.010318    2.199147  590981.360000       7.594302          0.215448   \n",
       "std      0.003874    0.004088    2881.596648      38.580495          0.014520   \n",
       "min    150.002524    2.191851  585578.000000      -0.078000          0.095000   \n",
       "25%    150.007165    2.195593  588399.750000       0.363500          0.217000   \n",
       "50%    150.010619    2.199306  591215.000000       0.970500          0.218000   \n",
       "75%    150.013524    2.202758  593364.500000       3.500000          0.219000   \n",
       "max    150.017355    2.207602  596794.000000     374.985000          0.231000   \n",
       "\n",
       "          photoz  splash_1_mag  splash_1_magerr  splash_1_flux  \\\n",
       "count  96.000000     96.000000        96.000000      97.000000   \n",
       "mean    1.233854     23.413717         0.075627       7.649175   \n",
       "std     0.815265      1.888851         0.096670      21.369673   \n",
       "min     0.000000     18.301000         0.005300      -0.016000   \n",
       "25%     0.751250     21.992375         0.015350       0.447000   \n",
       "50%     0.985500     23.798450         0.044600       1.036000   \n",
       "75%     1.643750     24.753875         0.099250       5.636000   \n",
       "max     3.895000     27.274900         0.596800     173.615000   \n",
       "\n",
       "       splash_1_flux_err  ...  mag_galex_nuv  magerr_galex_nuv  mag_galex_fuv  \\\n",
       "count          97.000000  ...      32.000000         32.000000      10.000000   \n",
       "mean            0.090619  ...      25.905962          1.148162      24.977410   \n",
       "std             0.161176  ...       1.719588          1.527069       1.607946   \n",
       "min             0.012000  ...      22.457100          0.026200      22.847600   \n",
       "25%             0.037000  ...      24.860825          0.170325      23.312050   \n",
       "50%             0.052000  ...      26.219200          0.648500      25.765250   \n",
       "75%             0.077000  ...      27.148450          1.422025      26.211375   \n",
       "max             1.455000  ...      28.903600          7.206000      26.790400   \n",
       "\n",
       "       magerr_galex_fuv        dist       angle   COSMOS_01   COSMOS_02  \\\n",
       "count         10.000000  100.000000  100.000000  100.000000  100.000000   \n",
       "mean           0.309080   19.272429  171.621108    0.440843    0.433247   \n",
       "std            0.281957    6.817253   96.033885    0.003903    0.003984   \n",
       "min            0.043300    2.219884    1.327525    0.432705    0.425733   \n",
       "25%            0.048625   14.629402  102.408427    0.437680    0.430057   \n",
       "50%            0.277450   19.451089  166.727549    0.441183    0.433150   \n",
       "75%            0.466375   25.166258  246.121820    0.443729    0.436673   \n",
       "max            0.767200   29.821238  359.357019    0.448870    0.442081   \n",
       "\n",
       "        COSMOS_03   COSMOS_04  \n",
       "count  100.000000  100.000000  \n",
       "mean     0.292982    0.281360  \n",
       "std      0.004073    0.003994  \n",
       "min      0.284810    0.273869  \n",
       "25%      0.289658    0.278412  \n",
       "50%      0.293005    0.281117  \n",
       "75%      0.296566    0.284188  \n",
       "max      0.300047    0.289890  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 76k with 15arcmin diameter IRAC images\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: InputWarning: Coordinate string is being interpreted as an ICRS coordinate provided in degrees. [astroquery.utils.commons]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Using the S3 STScI public dataset [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/mastDownload/GALEX/2550447100500377600/COSMOS_01-fd-int.fits.gz with expected size 19363143. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/mastDownload/GALEX/2550447100500377600/COSMOS_01-nd-int.fits.gz with expected size 21075310. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/mastDownload/GALEX/2550517469244555264/COSMOS_02-fd-int.fits.gz with expected size 19199230. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/mastDownload/GALEX/2550517469244555264/COSMOS_02-nd-int.fits.gz with expected size 21128583. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/mastDownload/GALEX/2550587837988732928/COSMOS_03-fd-int.fits.gz with expected size 20514253. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/mastDownload/GALEX/2550587837988732928/COSMOS_03-nd-int.fits.gz with expected size 21435391. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/mastDownload/GALEX/2550658206732910592/COSMOS_04-fd-int.fits.gz with expected size 19154899. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/mastDownload/GALEX/2550658206732910592/COSMOS_04-nd-int.fits.gz with expected size 21058127. [astroquery.mast.cloud]\n"
     ]
    }
   ],
   "source": [
    "#pull Galex mosaics from MAST\n",
    "# Get the observations you want\n",
    "in_coordinates = '150.01 2.20'\n",
    "observations = Observations.query_criteria(coordinates=in_coordinates, instrument_name='GALEX')\n",
    "\n",
    "filtered_observations = observations[(observations['t_exptime'] > 40000.0)]\n",
    "\n",
    "# Get the products for these observations \n",
    "products = Observations.get_product_list(filtered_observations)\n",
    "\n",
    "# Filter the products so we only download SCIENCE products\n",
    "filtered_products = Observations.filter_products(\n",
    "    products, productType='SCIENCE', productGroupDescription='Minimum Recommended Products'\n",
    ")\n",
    "\n",
    "# Enable cloud access\n",
    "Observations.enable_cloud_dataset(provider='AWS')\n",
    "\n",
    "# Download filtered products\n",
    "# Then, as a temporarily measure, flatten out the directory structure with symlinks (to avoid downloading again)\n",
    "download_dir = '../data/Galex/'\n",
    "downloaded_galex = Observations.download_products(filtered_products, cloud_only=True, download_dir=download_dir) \n",
    "\n",
    "for infile in downloaded_galex['Local Path']:\n",
    "    flat_file_path = f'{download_dir}/{os.path.basename(infile)}'\n",
    "    if not os.path.exists(flat_file_path):\n",
    "        os.symlink(re.split(download_dir, infile)[1], flat_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: InputWarning: Coordinate string is being interpreted as an ICRS coordinate provided in degrees. [astroquery.utils.commons]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Found cached file ../data/Galex/COSMOS_01-fd-skybg.fits.gz with expected size 4634459. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/COSMOS_01-nd-skybg.fits.gz with expected size 3643688. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/COSMOS_02-fd-skybg.fits.gz with expected size 4004168. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/COSMOS_02-nd-skybg.fits.gz with expected size 3511110. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/COSMOS_03-fd-skybg.fits.gz with expected size 4816730. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/COSMOS_03-nd-skybg.fits.gz with expected size 3477163. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/COSMOS_04-fd-skybg.fits.gz with expected size 3965837. [astroquery.mast.cloud]\n",
      "INFO: Found cached file ../data/Galex/COSMOS_04-nd-skybg.fits.gz with expected size 3475750. [astroquery.mast.cloud]\n"
     ]
    }
   ],
   "source": [
    "# Get the GALEX skybg fits files in addition to the mosaics\n",
    "\n",
    "in_coordinates = '150.01 2.20'\n",
    "observations = Observations.query_criteria(coordinates=in_coordinates, instrument_name='GALEX')\n",
    "\n",
    "# get products of said observations \n",
    "products = Observations.get_product_list(observations)\n",
    "\n",
    "# filtering for the few products we know we need, TODO: clean this up to be less arbitrary\n",
    "skybg_products = []\n",
    "skybkg_pattern = re.compile(r\"COSMOS_0[1-4]-[fn]d-skybg\")\n",
    "\n",
    "for row in products['dataURI']:\n",
    "    if skybkg_pattern.search(row): \n",
    "        skybg_products.append(row)\n",
    "        # local_path has to be a filename, see bug https://github.com/astropy/astroquery/issues/2501\n",
    "        Observations.download_file(row, local_path=f'../data/Galex/{os.path.basename(row)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ra                     0\n",
       "dec                    0\n",
       "clon                   0\n",
       "clat                   0\n",
       "id                     0\n",
       "ks_flux_aper2          4\n",
       "ks_fluxerr_aper2       4\n",
       "photoz                 4\n",
       "splash_1_mag           4\n",
       "splash_1_magerr        4\n",
       "splash_1_flux          3\n",
       "splash_1_flux_err      3\n",
       "splash_2_flux          4\n",
       "splash_2_flux_err      4\n",
       "splash_3_flux          2\n",
       "splash_3_flux_err      2\n",
       "splash_4_flux          0\n",
       "splash_4_flux_err      0\n",
       "flux_galex_nuv        68\n",
       "flux_galex_fuv        90\n",
       "flux_chandra_05_2     99\n",
       "flux_chandra_2_10     99\n",
       "flux_chandra_05_10    99\n",
       "id_chandra09          99\n",
       "type                   0\n",
       "r_mag_auto             0\n",
       "r_magerr_auto          0\n",
       "flux_24               95\n",
       "fluxerr_24            95\n",
       "mag_galex_nuv         68\n",
       "magerr_galex_nuv      68\n",
       "mag_galex_fuv         90\n",
       "magerr_galex_fuv      90\n",
       "dist                   0\n",
       "angle                  0\n",
       "COSMOS_01              0\n",
       "COSMOS_02              0\n",
       "COSMOS_03              0\n",
       "COSMOS_04              0\n",
       "galex_image            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure there aren't any troublesome rows in the catalog\n",
    "#are there missing values in any rows?\n",
    "df.isna().sum()\n",
    "\n",
    "#don't mind that there are missing values for some of the fluxes\n",
    "#The rest of the rows are complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    96\n",
       "1     3\n",
       "2     1\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out of curiosity how many of each type of source are in this catalog\n",
    "#Type: 0 = galaxy, 1 = star, 2 = X-ray source, -9 is failure to fit\n",
    "df.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Run Forced Photometry\n",
    "- Calculate a flux at a given position in 2 IRAC and 2 Galex bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Setup\n",
    "- initialize data frame columns to hold the results\n",
    "- collect the parameters for each band/channel\n",
    "- collect the input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize columns in data frame for photometry results\n",
    "cols = [\"ch1flux\", \"ch1flux_unc\", \"ch2flux\", \"ch2flux_unc\", \"ch3flux\", \"ch3flux_unc\",\n",
    "        \"ch4flux\", \"ch4flux_unc\", \"ch5flux\", \"ch5flux_unc\", \"ch6flux\", \"ch6flux_unc\"]\n",
    "df[cols] = 0.0\n",
    "\n",
    "# list to collect all the bands\n",
    "all_bands = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRAC channels\n",
    "\n",
    "irac_band_indexes = [\n",
    "    0,  # ch1\n",
    "    1,  # ch2\n",
    "    2,  # ch3\n",
    "    3,  # ch4\n",
    "]\n",
    "\n",
    "irac_fluxconversion = (1E12) / (4.254517E10) * (0.6) *(0.6)\n",
    "\n",
    "irac_mosaic_pix_scale = 0.6\n",
    "\n",
    "irac_cutout_width = 10 # in arcseconds, taken from Nyland et al. 2017\n",
    "\n",
    "irac_prfs = [\n",
    "    fits.open('../data/IRAC/PRF_IRAC_ch1.fits')[0].data,\n",
    "    fits.open('../data/IRAC/PRF_IRAC_ch2.fits')[0].data,\n",
    "    fits.open('../data/IRAC/PRF_IRAC_ch3.fits')[0].data,\n",
    "    fits.open('../data/IRAC/PRF_IRAC_ch4.fits')[0].data,\n",
    "]\n",
    "\n",
    "# zip parameters for each band into a container and append to the master list\n",
    "irac_bands = [\n",
    "    Band(\n",
    "        idx, prf, irac_cutout_width, irac_fluxconversion, irac_mosaic_pix_scale\n",
    "    )\n",
    "    for idx, prf in zip(irac_band_indexes, irac_prfs)\n",
    "]\n",
    "all_bands += irac_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GALEX bands\n",
    "\n",
    "galex_band_indexes = [\n",
    "    4,  # nuv\n",
    "    5,  # fuv\n",
    "]\n",
    "\n",
    "galex_cutout_width = 40\n",
    "\n",
    "galex_fluxconversions = [\n",
    "    3.373E1,  # uJy. fudging this to make the numbers bigger for plotting later\n",
    "    1.076E2,  # uJy. fudging this to make the numbers bigger for plotting later\n",
    "]\n",
    "\n",
    "galex_mosaic_pix_scale = 1.5\n",
    "\n",
    "prf_nuv = fits.open(\"../data/Galex/PSFnuv_faint.fits\")[0].data\n",
    "prf_fuv = fits.open(\"../data/Galex/PSFfuv.fits\")[0].data\n",
    "prf_nuv = prf_nuv[0:119, 0:119]\n",
    "prf_fuv = prf_fuv[0:119, 0:119]\n",
    "\n",
    "#these are much larger than the cutouts we are using, so only keep the central region which is the size of our cutouts\n",
    "ngalex_pix = galex_cutout_width / galex_mosaic_pix_scale\n",
    "prf_cen = int(60)\n",
    "prf_nuv = prf_nuv[(prf_cen - int(ngalex_pix / 2) - 1) : (prf_cen + int(ngalex_pix / 2)),\n",
    "                  (prf_cen - int(ngalex_pix / 2) - 1) : (prf_cen + int(ngalex_pix / 2))]\n",
    "prf_fuv = prf_fuv[(prf_cen - int(ngalex_pix / 2) - 1) : (prf_cen + int(ngalex_pix / 2)),\n",
    "                  (prf_cen - int(ngalex_pix / 2) - 1) : (prf_cen + int(ngalex_pix / 2))]\n",
    "galex_prfs = [prf_nuv, prf_fuv]\n",
    "\n",
    "# zip parameters for each band into a container and append to the master list\n",
    "galex_bands = [\n",
    "    Band(\n",
    "        idx, prf, galex_cutout_width, flux_conv, galex_mosaic_pix_scale\n",
    "    )\n",
    "    for idx, prf, flux_conv in zip(galex_band_indexes, galex_prfs, galex_fluxconversions)\n",
    "]\n",
    "all_bands += galex_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect input images\n",
    "# collect the files in pairs: (science image, sky-background image)\n",
    "# if the same file should be used for both, just send it once\n",
    "sci_bkg_pairs = [\n",
    "    # IRAC. use the science image to calculate the background\n",
    "    ('../data/IRAC/irac_ch1_go2_sci_10.fits', ),\n",
    "    ('../data/IRAC/irac_ch2_go2_sci_10.fits', ),\n",
    "    ('../data/IRAC/irac_ch3_go2_sci_10.fits', ),\n",
    "    ('../data/IRAC/irac_ch4_go2_sci_10.fits', ),\n",
    "    # GALEX. calculate the background from a dedicated file\n",
    "    ('../data/Galex/COSMOS_01-nd-int.fits.gz', '../data/Galex/COSMOS_01-nd-skybg.fits.gz'),\n",
    "    ('../data/Galex/COSMOS_01-fd-int.fits.gz', '../data/Galex/COSMOS_01-fd-skybg.fits.gz'),\n",
    "    ('../data/Galex/COSMOS_02-nd-int.fits.gz', '../data/Galex/COSMOS_02-nd-skybg.fits.gz'),\n",
    "    ('../data/Galex/COSMOS_02-fd-int.fits.gz', '../data/Galex/COSMOS_02-fd-skybg.fits.gz'),\n",
    "    ('../data/Galex/COSMOS_03-nd-int.fits.gz', '../data/Galex/COSMOS_03-nd-skybg.fits.gz'),\n",
    "    ('../data/Galex/COSMOS_03-fd-int.fits.gz', '../data/Galex/COSMOS_03-fd-skybg.fits.gz'),\n",
    "    ('../data/Galex/COSMOS_04-nd-int.fits.gz', '../data/Galex/COSMOS_04-nd-skybg.fits.gz'),\n",
    "    ('../data/Galex/COSMOS_04-fd-int.fits.gz', '../data/Galex/COSMOS_04-fd-skybg.fits.gz'),\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Main Function to do the Forced Photometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_instrflux(band, ra, dec, stype, ks_flux_aper2, img_pair, df):\n",
    "    \"\"\"\n",
    "    Calculate single-band instrumental fluxes and uncertainties at the given ra, dec \n",
    "    using tractor.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    band : `Band`\n",
    "        Collection of parameters for a single band. \n",
    "        A `Band` is a named tuple with the following attributes:\n",
    "            idx : int\n",
    "                Identifier for the band/channel.\n",
    "                (integer in [0, 1, 2, 3, 4, 5] for the four IRAC bands and two Galex bands)\n",
    "            prf : np.ndarray\n",
    "                Point spread function for the band/channel.\n",
    "            cutout_width : int\n",
    "                width of desired cutout in arcseconds\n",
    "            flux_conv : float\n",
    "                factor used to convert tractor result to microjanskies\n",
    "            mosaic_pix_scale : float\n",
    "                Pixel scale of the image\n",
    "    ra, dec : float\n",
    "        celestial coordinates for measuring photometry\n",
    "    stype : int\n",
    "        0, 1, 2, -9 for star, galaxy, x-ray source\n",
    "    ks_flux_aper_2 : float\n",
    "        flux in aperture 2\n",
    "    img_pair : tuple\n",
    "        Pair of images for science and background respectively.\n",
    "        If the tuple only contains one element it will serve double duty.\n",
    "        A tuple element can be a `fits.ImageHDU` or the path to a FITS file as a `str`.\n",
    "    df : pd.DataFrame\n",
    "        Source catalog.\n",
    "        Previous arguments (ra, dec, stype, ks_flux_aper_2) come from a single row of this df.\n",
    "        However, we must also pass the entire dataframe in order to find nearby sources which are possible contaminates.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    outband : int\n",
    "        reflects the input band index for identification purposes\n",
    "    flux : float\n",
    "        Measured flux in microJansky.\n",
    "        NaN if the forced photometery failed.\n",
    "    flux_unc : float\n",
    "        Flux uncertainty in microJansky, calculated from the tractor results.\n",
    "        NaN if the forced photometery failed or if tractor didn't report a flux variance.\n",
    "    \"\"\"\n",
    "    # cutout a small region around the object of interest\n",
    "    subimage, bkgsubimage, x1, y1, subimage_wcs = cutout.extract_pair(\n",
    "        ra, dec, img_pair=img_pair, cutout_width=band.cutout_width, mosaic_pix_scale=band.mosaic_pix_scale\n",
    "    )\n",
    "    \n",
    "    # find nearby sources that are possible contaminants\n",
    "    objsrc, nconfsrcs = find_nconfsources(\n",
    "        ra, dec, stype, ks_flux_aper2, x1, y1, band.cutout_width, subimage_wcs, df\n",
    "    )\n",
    "\n",
    "    # estimate the background\n",
    "    skymean, skynoise = photometry.calc_background(bkgsubimage=bkgsubimage)\n",
    "\n",
    "    # do the forced photometry\n",
    "    # if tractor fails to converge, just return NaNs\n",
    "    try:\n",
    "        flux_var = photometry.run_tractor(\n",
    "            subimage=subimage, prf=band.prf, objsrc=objsrc, skymean=skymean, skynoise=skynoise\n",
    "        )\n",
    "    except TractorError:\n",
    "        return (band.idx, np.nan, np.nan)\n",
    "\n",
    "    # convert the results\n",
    "    microJy_flux, microJy_unc = photometry.interpret_tractor_results(\n",
    "        flux_var=flux_var, flux_conv=band.flux_conv, objsrc=objsrc, nconfsrcs=nconfsrcs\n",
    "    )\n",
    "\n",
    "    return (band.idx, microJy_flux, microJy_unc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Calculate Forced Photometry with Straightforward but Slow Method\n",
    "- no longer in use but keeping to demonstrate this capability\\\n",
    "as well as the increase in speed when going to parallelization"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%time\n",
    "#do the calculation without multiprocessing for benchmarking\n",
    "\n",
    "#make a copy for parallel computation\n",
    "pl_df = df.copy(deep=True)\n",
    "\n",
    "t0 = time.time()\n",
    "#for each object\n",
    "for row in df.itertuples():\n",
    "    #for each band\n",
    "    for band in range(6):\n",
    "        #measure the flux with tractor\n",
    "        outband, flux, unc = calc_instrflux(band, row.ra, row.dec, row.type, row.ks_flux_aper2)\n",
    "        #put the results back into the dataframe\n",
    "        df.loc[row.Index, 'ch{:d}flux'.format(outband+1)] = flux\n",
    "        df.loc[row.Index, 'ch{:d}flux_unc'.format(outband+1)] = unc\n",
    "        #print(row.ra, row.dec, row.type, row.ks_flux_aper2, band+1,\n",
    "        #      outband, flux, unc)\n",
    "t1 = time.time()\n",
    "\n",
    "\n",
    "#10,000 sources took 1.5 hours with this code on the IPAC SP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d. Calculate Forced Photometry - Parallelization\n",
    "- Parallelization: we can either interate over the rows of the dataframe and run the four bands in parallel; or we could zip together the row index, band, ra, dec, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramlist = []\n",
    "for row in df.itertuples():\n",
    "    for band in all_bands:\n",
    "        img_pair = lookup_img_pair(sci_bkg_pairs, band.idx, row.galex_image)  # file paths only\n",
    "        paramlist.append(\n",
    "            [row.Index, band, row.ra, row.dec, row.type, row.ks_flux_aper2, img_pair, df]\n",
    "        )            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/IRAC/irac_ch1_go2_sci_10.fits'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#proove we can do this for one object\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcalc_instrflux\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparamlist\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36mcalc_instrflux\u001b[0;34m(band, ra, dec, stype, ks_flux_aper2, img_pair, df)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mCalculate single-band instrumental fluxes and uncertainties at the given ra, dec \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03musing tractor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    NaN if the forced photometery failed or if tractor didn't report a flux variance.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# cutout a small region around the object of interest\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m subimage, bkgsubimage, x1, y1, subimage_wcs \u001b[38;5;241m=\u001b[39m \u001b[43mcutout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_pair\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutout_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mband\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcutout_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmosaic_pix_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mband\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmosaic_pix_scale\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# find nearby sources that are possible contaminants\u001b[39;00m\n\u001b[1;32m     54\u001b[0m objsrc, nconfsrcs \u001b[38;5;241m=\u001b[39m find_nconfsources(\n\u001b[1;32m     55\u001b[0m     ra, dec, stype, ks_flux_aper2, x1, y1, band\u001b[38;5;241m.\u001b[39mcutout_width, subimage_wcs, df\n\u001b[1;32m     56\u001b[0m )\n",
      "File \u001b[0;32m~/forced_photometry/fornax-demo-notebooks/fornax-demo-notebooks/forced_photometry/../code/cutout.py:39\u001b[0m, in \u001b[0;36mextract_pair\u001b[0;34m(ra, dec, img_pair, cutout_width, mosaic_pix_scale)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# extract science image cutout\u001b[39;00m\n\u001b[1;32m     38\u001b[0m img \u001b[38;5;241m=\u001b[39m img_pair[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 39\u001b[0m subimage, x1, y1, subimage_wcs \u001b[38;5;241m=\u001b[39m \u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43mra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutout_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcutout_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmosaic_pix_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmosaic_pix_scale\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# extract sky background cutout\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# if there's only 1 HDU in the \"pair\", it doubles for the background\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(img_pair) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/forced_photometry/fornax-demo-notebooks/fornax-demo-notebooks/forced_photometry/../code/cutout.py:83\u001b[0m, in \u001b[0;36mextract\u001b[0;34m(ra, dec, hdu, cutout_width, mosaic_pix_scale)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m'''Extract an image cutout from `hdu` at `ra` and `dec`.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m    `WCS` for the cutout.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(hdu, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# hdu is a file path. load the primary HDU\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     hdu \u001b[38;5;241m=\u001b[39m \u001b[43mfits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdu\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     84\u001b[0m wcs_info \u001b[38;5;241m=\u001b[39m WCS(hdu)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# convert ra and dec into x, y\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/tractor/lib/python3.10/site-packages/astropy/io/fits/hdu/hdulist.py:175\u001b[0m, in \u001b[0;36mfitsopen\u001b[0;34m(name, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmpty filename: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHDUList\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/tractor/lib/python3.10/site-packages/astropy/io/fits/hdu/hdulist.py:410\u001b[0m, in \u001b[0;36mHDUList.fromfile\u001b[0;34m(cls, fileobj, mode, memmap, save_backup, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfromfile\u001b[39m(\u001b[38;5;28mcls\u001b[39m, fileobj, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, memmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m              save_backup\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, lazy_load_hdus\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    401\u001b[0m              ignore_missing_simple\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03m    Creates an `HDUList` instance from a file-like object.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m    documentation for details of the parameters accepted by this method).\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readfrom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m                         \u001b[49m\u001b[43msave_backup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_backup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mignore_missing_simple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_missing_simple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlazy_load_hdus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/tractor/lib/python3.10/site-packages/astropy/io/fits/hdu/hdulist.py:1060\u001b[0m, in \u001b[0;36mHDUList._readfrom\u001b[0;34m(cls, fileobj, data, mode, memmap, cache, lazy_load_hdus, ignore_missing_simple, **kwargs)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, _File):\n\u001b[1;32m   1059\u001b[0m         \u001b[38;5;66;03m# instantiate a FITS file object (ffo)\u001b[39;00m\n\u001b[0;32m-> 1060\u001b[0m         fileobj \u001b[38;5;241m=\u001b[39m \u001b[43m_File\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m     \u001b[38;5;66;03m# The Astropy mode is determined by the _File initializer if the\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;66;03m# supplied mode was None\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     mode \u001b[38;5;241m=\u001b[39m fileobj\u001b[38;5;241m.\u001b[39mmode\n",
      "File \u001b[0;32m/srv/conda/envs/tractor/lib/python3.10/site-packages/astropy/io/fits/file.py:170\u001b[0m, in \u001b[0;36m_File.__init__\u001b[0;34m(self, fileobj, mode, memmap, overwrite, cache)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_fileobj(fileobj, mode, overwrite)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fileobj, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_filename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open_filelike(fileobj, mode, overwrite)\n",
      "File \u001b[0;32m/srv/conda/envs/tractor/lib/python3.10/site-packages/astropy/io/fits/file.py:562\u001b[0m, in \u001b[0;36m_File._open_filename\u001b[0;34m(self, filename, mode, overwrite)\u001b[0m\n\u001b[1;32m    559\u001b[0m ext \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_read_compressed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, magic, mode, ext\u001b[38;5;241m=\u001b[39mext):\n\u001b[0;32m--> 562\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIO_FITS_MODES\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose_on_error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;66;03m# Make certain we're back at the beginning of the file\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;66;03m# BZ2File does not support seek when the file is open for writing, but\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# when opening a file for write, bz2.BZ2File always truncates anyway.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/IRAC/irac_ch1_go2_sci_10.fits'"
     ]
    }
   ],
   "source": [
    "#proove we can do this for one object\n",
    "calc_instrflux(*paramlist[0][1:])\n",
    "\n",
    "#same thing, different syntax\n",
    "# calc_instrflux(paramlist[0][1], paramlist[0][2], paramlist[0][3], paramlist[0][4], paramlist[0][5], paramlist[0][6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapper to measure the photometry on a single object, single band\n",
    "def calculate_flux(args):\n",
    "    \"\"\"Calculate flux.\"\"\"\n",
    "    f = calc_instrflux\n",
    "    val = f(*args[1:])\n",
    "    return(args[0], val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Here is where the multiprocessing work gets done\n",
    "t2 = time.time()\n",
    "outputs = []\n",
    "# number of processes can be controlled with a max_workers arg in ProcessPoolExecutor\n",
    "# defaults to the number of available processors, beyond which no performance gains are seen\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    for result in list(tqdm(executor.map(calculate_flux, paramlist), total = len(paramlist))):\n",
    "        # print(result)\n",
    "        df.loc[result[0],\n",
    "                  'ch{:d}flux'.format(result[1][0] + 1)] = result[1][1]\n",
    "        df.loc[result[0],\n",
    "                  'ch{:d}flux_unc'.format(result[1][0] + 1)] = result[1][2]\n",
    "        outputs.append(result)\n",
    "t3 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Serial calculation took {:.2f} seconds'.format((t1 - t0)))\n",
    "print('Parallel calculation took {:.2f} seconds'.format((t3 - t2)))\n",
    "#print('Speedup is {:.2f}'.format((t1 - t0) / (t3 - t2)))\n",
    "\n",
    "#speedup was factors of 10 - 12 for 400 - 10000 sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of non-zero ch1 fluxes\n",
    "#print('Serial calculation: number of ch1 fluxes filled in =',\n",
    "#      np.sum(df.ch1flux > 0))\n",
    "print('Parallel calculation: number of ch1 fluxes filled in =',\n",
    "      np.sum(df.ch1flux > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3e. Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#had to call the galex flux columns ch5 and ch6\n",
    "#fix that by renaming them now\n",
    "cols = {'ch5flux':'nuvflux', 'ch5flux_unc':'nuvflux_unc','ch6flux':'fuvflux', 'ch6flux_unc':'fuvflux_unc'}\n",
    "df.rename(columns=cols, inplace = True)\n",
    "#pl_df.rename(columns={'ch5flux':'nuvflux', 'ch5flux_unc':'nuvflux_unc','ch6flux':'fuvflux', 'ch6flux_unc':'fuvflux_unc'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When doing a large run of a large area, save the dataframe with the forced photometry \n",
    "# so we don't have to do the forced photometry every time\n",
    "\n",
    "df.to_pickle('../data/COSMOS_15arcmin.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you are not runnig the forced photometry, then read in the catalog from a previous run\n",
    "\n",
    "#df = pd.read_pickle('../data/COSMOS_15arcmin.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3f. Plot to Confirm our Photometry Results \n",
    "- compare to published COSMOS 2015 catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#plot tractor fluxes vs. catalog splash fluxes\n",
    "#should see a straightline with a slope of 1\n",
    "\n",
    "#setup to plot\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "fluxmax = 200\n",
    "ymax = 100\n",
    "xmax = 100\n",
    "#ch1 \n",
    "#first shrink the dataframe to only those rows where I have tractor photometry \n",
    "df_tractor = df[(df.splash_1_flux> 0) & (df.splash_1_flux < fluxmax)] #200\n",
    "#sns.regplot(data = df_tractor, x = \"splash_1_flux\", y = \"ch1flux\", ax = ax1, robust = True)\n",
    "sns.scatterplot(data = df_tractor, x = \"splash_1_flux\", y = \"ch1flux\", ax = ax1)\n",
    "\n",
    "#add a diagonal line with y = x\n",
    "lims = [\n",
    "    np.min([ax1.get_xlim(), ax1.get_ylim()]),  # min of both axes\n",
    "    np.max([ax1.get_xlim(), ax1.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax1.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax1.set(xlabel = 'COSMOS 2015 flux ($\\mu$Jy)', ylabel = 'tractor flux ($\\mu$Jy)', title = 'IRAC 3.6')\n",
    "ax1.set_ylim([0, ymax])\n",
    "ax1.set_xlim([0, xmax])\n",
    "\n",
    "\n",
    "#ch2 \n",
    "#first shrink the dataframe to only those rows where I have tractor photometry \n",
    "df_tractor = df[(df.splash_2_flux> 0) & (df.splash_2_flux < fluxmax)]\n",
    "#sns.regplot(data = df_tractor, x = \"splash_2_flux\", y = \"ch2flux\", ax = ax2, robust = True)\n",
    "sns.scatterplot(data = df_tractor, x = \"splash_2_flux\", y = \"ch2flux\", ax = ax2)\n",
    "\n",
    "#add a diagonal line with y = x\n",
    "lims = [\n",
    "    np.min([ax2.get_xlim(), ax2.get_ylim()]),  # min of both axes\n",
    "    np.max([ax2.get_xlim(), ax2.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax2.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax2.set(xlabel = 'COSMOS 2015 flux ($\\mu$Jy)', ylabel = 'tractor flux ($\\mu$Jy)', title = 'IRAC 4.5')\n",
    "ax2.set_ylim([0, ymax])\n",
    "ax2.set_xlim([0, xmax])\n",
    "\n",
    "\n",
    "#ch3 \n",
    "#first shrink the dataframe to only those rows where I have tractor photometry\n",
    "df_tractor = df[(df.splash_3_flux> 0) & (df.splash_3_flux < fluxmax)]\n",
    "\n",
    "#sns.regplot(data = df_tractor, x = \"splash_3_flux\", y = \"ch3flux\", ax = ax3, robust = True)\n",
    "sns.scatterplot(data = df_tractor, x = \"splash_3_flux\", y = \"ch3flux\", ax = ax3)\n",
    "\n",
    "#add a diagonal line with y = x\n",
    "lims = [\n",
    "    np.min([ax3.get_xlim(), ax3.get_ylim()]),  # min of both axes\n",
    "    np.max([ax3.get_xlim(), ax3.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax3.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax3.set(xlabel = 'COSMOS 2015 flux ($\\mu$Jy)', ylabel = 'tractor flux ($\\mu$Jy)', title = 'IRAC 5.8')\n",
    "ax3.set_ylim([0, ymax])\n",
    "ax3.set_xlim([0, xmax])\n",
    "\n",
    "\n",
    "#ch4 \n",
    "#first shrink the dataframe to only those rows where I have tractor photometry \n",
    "df_tractor = df[(df.splash_4_flux> 0) & (df.splash_4_flux < fluxmax)]\n",
    "\n",
    "#sns.regplot(data = df_tractor, x = \"splash_4_flux\", y = \"ch4flux\", ax = ax4, robust = True)\n",
    "sns.scatterplot(data = df_tractor, x = \"splash_4_flux\", y = \"ch4flux\", ax = ax4)\n",
    "\n",
    "#add a diagonal line with y = x\n",
    "lims = [\n",
    "    np.min([ax4.get_xlim(), ax4.get_ylim()]),  # min of both axes\n",
    "    np.max([ax4.get_xlim(), ax4.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax4.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax4.set(xlabel = 'COSMOS 2015 flux ($\\mu$Jy)', ylabel = 'tractor flux ($\\mu$Jy)', title = 'IRAC 8.0')\n",
    "ax4.set_ylim([0, ymax])\n",
    "ax4.set_xlim([0, xmax])\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.subplots_adjust( hspace=0.5)\n",
    "fig.set_size_inches(8, 12)\n",
    "\n",
    "#plt.savefig('flux_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tractor is working for IRAC; Comparison of tractor derived fluxes with COSMOS 2015 fluxes for all four Spitzer IRAC channels.  Blue points represent each object from the subset of the COSMOS 2015 catalog.  The blue line is a linear regression robust fit to the data with uncertainties shown as the light blue wedge.  The black line is a y = x line plotted to guide the eye."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross Match our New Photometry Catalog with an X-ray archival Catalog\n",
    "We are using `nway` as the tool to do the cross match (Salvato et al. 2017).\n",
    "`nway` expects input as two fits table files and outputs a third table file with all the possible matches and their probabilities of being the correct match.  We then sort that catalog and take only the best matches to be the true matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Retrieve the HEASARC Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first get an X-ray catalog from Heasarc\n",
    "heasarc = Heasarc()\n",
    "table = heasarc.query_mission_list()\n",
    "mask = (table['Mission'] ==\"CHANDRA\")\n",
    "chandratable = table[mask]  \n",
    "\n",
    "#find out which tables exist on Heasarc\n",
    "#chandratable.pprint(max_lines = 200, max_width = 130)\n",
    "\n",
    "#want ccosmoscat\n",
    "mission = 'ccosmoscat'\n",
    "#coords already defined above where I pull the original COSMOS catalog\n",
    "ccosmoscat_rad = 1 #radius of chandra cosmos catalog\n",
    "ccosmoscat = heasarc.query_region(coords, mission=mission, radius='1 degree', resultmax = 5000, fields = \"ALL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Run `nway` to do the Cross-Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup:\n",
    "\n",
    "#astropy doesn't recognize capitalized units\n",
    "#so there might be some warnings here on writing out the file, but we can safely ignore those\n",
    "\n",
    "#need to make the chandra catalog into a fits table \n",
    "#and needs to include area of the survey.\n",
    "nway_write_header('../data/Chandra/COSMOS_chandra.fits', 'CHANDRA', float(ccosmoscat_rad**2) )\n",
    "\n",
    "\n",
    "#also need to transform the main pandas dataframe into fits table for nway\n",
    "#make an index column for tracking later\n",
    "df['ID'] = range(1, len(df) + 1)\n",
    "\n",
    "#need this to be a fits table and needs to include area of the survey.\n",
    "rad_in_arcmin = radius.value  #units attached to this are confusing nway down the line\n",
    "nway_write_header('../data/multiband_phot.fits', 'OPT', float((2*rad_in_arcmin/60)**2) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call nway\n",
    "#!/home/jovyan/.local/bin/nway.py '../data/Chandra/COSMOS_chandra.fits' :ERROR_RADIUS '../data/multiband_phot.fits' 0.1 --out=../data/Chandra/chandra_multiband.fits --radius 15 --prior-completeness 0.9\n",
    "    \n",
    "!/opt/conda/bin/nway.py '../data/Chandra/COSMOS_chandra.fits' :ERROR_RADIUS '../data/multiband_phot.fits' 0.1 --out=../data/Chandra/chandra_multiband.fits --radius 15 --prior-completeness 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up the cross match results and merge them back into main pandas dataframe\n",
    "\n",
    "#read in the nway matched catalog\n",
    "xmatch = Table.read('../data/Chandra/chandra_multiband.fits', hdu = 1)\n",
    "df_xmatch = xmatch.to_pandas()\n",
    "\n",
    "#manual suggests that p_i should be greater than 0.1 for a pure catalog.\n",
    "#The matched catalog has multiple optical associations for some of the XMM detections.\n",
    "#simplest thing to do is only keep match_flag = 1\n",
    "matched = df_xmatch.loc[(df_xmatch['p_i']>=0.1) & df_xmatch['match_flag']==1]\n",
    "\n",
    "#merge this info back into the df_optical dataframe.\n",
    "merged = pd.merge(df, matched, 'outer',left_on='ID', right_on = 'OPT_ID')\n",
    "\n",
    "#remove all the rows which start with \"OPT\" because they are duplications of the original catalog\n",
    "merged = merged.loc[:, ~merged.columns.str.startswith('OPT')]\n",
    "\n",
    "#somehow the matching is giving negative fluxes in the band where there is no detection \n",
    "#if there is a detection in the other band\n",
    "#clean that up to make those negative fluxes = 0\n",
    "\n",
    "merged.loc[merged['flux_chandra_2_10'] < 0, 'flux_chandra_2_10'] = 0\n",
    "merged.loc[merged['flux_chandra_05_2'] < 0, 'flux_chandra_05_2'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many Chandra sources are there?\n",
    "#How many Galex sources are there?\n",
    "\n",
    "#make a new column which is a bool of existing chandra measurements\n",
    "merged['chandra_detect'] = 0\n",
    "merged.loc[merged.CHANDRA_FLUX > 0,'chandra_detect']=1\n",
    "\n",
    "#make one for Galex too\n",
    "merged['galex_detect'] = 0\n",
    "merged.loc[merged.flux_galex_nuv > 0,'galex_detect']=1\n",
    "\n",
    "\n",
    "print('number of Chandra detections =',np.sum(merged.chandra_detect > 0))\n",
    "print('number of Galex detections =',np.sum(merged.galex_detect > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot Final Results\n",
    "- We want to understand something about populations based on their colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IRAC color color plots akin to Lacy et al. 2004\n",
    "#overplot galex sources\n",
    "#overplot xray sources\n",
    "\n",
    "#first select on 24 micron \n",
    "merged_24 = merged[(merged.flux_24 >= 0) ] \n",
    "\n",
    "#negative Galex fluxes are causing problems, so set those to zero\n",
    "merged_24.loc[merged_24.fuvflux < 0, 'fuvflux'] = 0\n",
    "merged_24.loc[merged_24.nuvflux < 0, 'nuvflux'] = 0\n",
    "\n",
    "#make color columns\n",
    "merged_24['F5.8divF3.6'] = merged_24.ch3flux / merged_24.ch1flux\n",
    "merged_24['F8.0divF4.5'] = merged_24.ch4flux / merged_24.ch2flux\n",
    "\n",
    "#detected in all IRAC bands\n",
    "merged_allirac = merged_24[(merged_24['F8.0divF4.5'] > 0) & (merged_24['F5.8divF3.6'] > 0)]\n",
    "\n",
    "#plot all the points\n",
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(data = merged_allirac, x = 'F5.8divF3.6', y = 'F8.0divF4.5',\n",
    "                 ax = ax, alpha = 0.5, label = 'all')\n",
    "\n",
    "#plot only those points with Galex detections\n",
    "galex_detect = merged_allirac[merged_allirac.galex_detect > 0]\n",
    "sns.scatterplot(data = galex_detect, x = 'F5.8divF3.6', y = 'F8.0divF4.5',\n",
    "                 ax = ax, alpha = 0.5, label = 'Galex detect')\n",
    "\n",
    "#plot only those points with chandra detections\n",
    "chandra_detect = merged_allirac[merged_allirac.chandra_detect > 0]\n",
    "sns.scatterplot(data = chandra_detect, x = 'F5.8divF3.6', y = 'F8.0divF4.5',\n",
    "                 ax = ax, label = 'Chandra detect')\n",
    "\n",
    "\n",
    "\n",
    "ax.set(xscale=\"log\", yscale=\"log\")\n",
    "ax.set_ylim([0.1, 10])\n",
    "ax.set_xlim([0.1, 10])\n",
    "\n",
    "ax.set(xlabel = 'log F5.8/F3.6', ylabel = 'log F8.0/F4.5')\n",
    "ax.legend(loc='lower right')\n",
    "plt.title('IRAC Color Color Plot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows an IRAC color color plot akin to the seminal work by Lacy et al. 2004.  Points are color coded for those with Galex UV detections and those with Chandra x-ray detections. Note that the different populations are seperating out in this color color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UV IR color color plot akin to Bouquin et al. 2015\n",
    "fig, ax = plt.subplots()\n",
    "merged['FUV-NUV'] = merged.mag_galex_fuv - merged.mag_galex_nuv\n",
    "merged['NUV-3.6'] = merged.mag_galex_nuv - merged.splash_1_mag\n",
    "\n",
    "\n",
    "#plot all the points\n",
    "#sns.scatterplot(data = merged, x = 'NUV-3.6', y = 'FUV-NUV',\n",
    "#                 ax = ax, alpha = 0.5)\n",
    "\n",
    "#plot only those points with Galex detections\n",
    "galex_detect = merged[merged.galex_detect > 0]\n",
    "sns.kdeplot(data = galex_detect, x = 'NUV-3.6', y = 'FUV-NUV',\n",
    "            ax = ax, fill = True, levels = 15)#scatterplot , alpha = 0.5\n",
    "\n",
    "#plot only those points with chandra detections\n",
    "#now with color coding Chandra sources by hardness ratio a la Moutard et al. 2020\n",
    "chandra_detect = merged[merged.chandra_detect > 0]\n",
    "sns.scatterplot(data = chandra_detect, x = 'NUV-3.6', y = 'FUV-NUV',\n",
    "                ax = ax, hue= 'CHANDRA_HARDNESS_RATIO',palette=\"flare\")\n",
    "\n",
    "#whew that legend for the hue is terrible\n",
    "#try making it into a colorbar outside the plot instead\n",
    "norm = plt.Normalize(merged['CHANDRA_HARDNESS_RATIO'].min(), merged['CHANDRA_HARDNESS_RATIO'].max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"flare\", norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Remove the legend and add a colorbar\n",
    "#ax.get_legend().remove()\n",
    "ax.figure.colorbar(sm)\n",
    "\n",
    "#ax.set(xscale=\"log\", yscale=\"log\")\n",
    "ax.set_ylim([-0.5, 3.5])\n",
    "ax.set_xlim([-1, 7])\n",
    "\n",
    "ax.set(xlabel = 'NUV - [3.6]', ylabel = 'FUV - NUV')\n",
    "#plt.legend([],[], frameon=False)\n",
    "\n",
    "#fig.savefig(\"../data/color_color.png\")\n",
    "mpld3.display(fig)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extend the works of Bouquin et al. 2015 and Moutard et al. 2020 by showing a GALEX - Spitzer color color diagram over plotted with Chandra detections.  Blue galaxies in these colors are generated by O and B stars and so must currently be forming stars. We find a tight blue cloud in this color space identifying those star forming galaxies.  Galaxies off of the blue cloud have had their star formation quenched, quite possibly by the existence of an AGN through removal of the gas reservoir required for star formation.  Chandra detected galaxies host AGN, and while those are more limited in number, can be shown here to be a hosted by all kinds of galaxies, including quiescent galaxies which would be in the upper right of this plot.  This likely implies that AGN are indeed involved in quenching star formation.  Additionally, we show the Chandra hardness ratio (HR) color coded according to the vertical color bar on the right side of the plot.  Those AGN with higher hardness ratios have their soft x-ray bands heavily obscured and appear to reside preferentially toward the quiescent galaxies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "This work made use of:\n",
    "\n",
    "- Astroquery; Ginsburg et al., 2019, 2019AJ....157...98G\n",
    "\n",
    "- Astropy; Astropy Collaboration 2022, Astropy Collaboration 2018, Astropy Collaboration 2013, 2022ApJ...935..167A, 2018AJ....156..123A, 2013A&A...558A..33A\n",
    "\n",
    "- The Tractor; Lang et al. 2016, 2016AJ....151...36L\n",
    "\n",
    "- Nyland et al. 2017 , 2017ApJS..230....9N\n",
    "\n",
    "- Salvato et al. 2018, 2018MNRAS.473.4937S\n",
    "\n",
    "- Laigle et al. 2016, 2016ApJS..224...24L\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tractor]",
   "language": "python",
   "name": "conda-env-tractor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
